[2024-05-09 10:00:28,198] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:00:28,352] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:00:28,352] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:01:29,910] INFO 127.0.0.1 - - [09/May/2024:03:01:29 +0000] "GET /connectors HTTP/1.1" 200 25 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 4 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:01:29,941] INFO 127.0.0.1 - - [09/May/2024:03:01:29 +0000] "GET /connectors/jdbc_source_oracle_01 HTTP/1.1" 200 377 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 4 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:01:29,981] INFO 127.0.0.1 - - [09/May/2024:03:01:29 +0000] "GET /connectors/jdbc_source_oracle_01/status HTTP/1.1" 200 2118 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 6 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:03:20,895] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://192.168.1.2:3306/tai_khoan
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [taikhoan]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = oracle_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:03:20,895] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:370)
[2024-05-09 10:03:20,900] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_oracle_01 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2024-05-09 10:03:20,901] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Handling connector-only config update by restarting connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2024-05-09 10:03:20,901] INFO [jdbc_source_oracle_01|worker] Stopping connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:03:20,901] INFO [jdbc_source_oracle_01|worker] Scheduled shutdown for WorkerConnector{id=jdbc_source_oracle_01} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2024-05-09 10:03:20,902] INFO [jdbc_source_oracle_01|worker] Completed shutdown for WorkerConnector{id=jdbc_source_oracle_01} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2024-05-09 10:03:20,903] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:03:20 +0000] "PUT /connectors/jdbc_source_oracle_01/config HTTP/1.1" 200 508 "-" "PostmanRuntime/7.37.0" 13 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:03:20,903] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 10:03:20,903] INFO [jdbc_source_oracle_01|worker] Creating connector jdbc_source_oracle_01 of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 10:03:20,904] INFO [jdbc_source_oracle_01|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = jdbc_source_oracle_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 10:03:20,904] INFO [jdbc_source_oracle_01|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = jdbc_source_oracle_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 10:03:20,905] INFO [jdbc_source_oracle_01|worker] Instantiated connector jdbc_source_oracle_01 with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 10:03:20,905] INFO [jdbc_source_oracle_01|worker] Finished creating connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 10:03:20,905] INFO [jdbc_source_oracle_01|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 10:03:20,905] INFO [jdbc_source_oracle_01|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://192.168.1.2:3306/tai_khoan
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [taikhoan]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = oracle_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:03:20,906] INFO [jdbc_source_oracle_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:03:20,906] INFO [jdbc_source_oracle_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:03:20,906] INFO [jdbc_source_oracle_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:03:20,906] INFO [jdbc_source_oracle_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:03:20,906] INFO [jdbc_source_oracle_01|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 10:03:20,906] INFO [jdbc_source_oracle_01|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:03:30,908] INFO [jdbc_source_oracle_01|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:03:40,909] ERROR [jdbc_source_oracle_01|worker] WorkerConnector{id=jdbc_source_oracle_01} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:03:40,910] ERROR [jdbc_source_oracle_01|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'jdbc_source_oracle_01' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_oracle_01
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector jdbc_source_oracle_01 to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:03:48,617] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://192.168.1.2:3306/tai_khoan
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [taikhoan]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:03:48,617] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:370)
[2024-05-09 10:03:48,622] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_oracle_01 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2024-05-09 10:03:48,622] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Handling connector-only config update by restarting connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2024-05-09 10:03:48,622] INFO [jdbc_source_oracle_01|worker] Stopping connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:03:48,622] INFO [jdbc_source_oracle_01|worker] Scheduled shutdown for WorkerConnector{id=jdbc_source_oracle_01} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2024-05-09 10:03:48,623] INFO [jdbc_source_oracle_01|worker] Completed shutdown for WorkerConnector{id=jdbc_source_oracle_01} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2024-05-09 10:03:48,623] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 10:03:48,624] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:03:48 +0000] "PUT /connectors/jdbc_source_oracle_01/config HTTP/1.1" 200 507 "-" "PostmanRuntime/7.37.0" 10 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:03:48,624] INFO [jdbc_source_oracle_01|worker] Creating connector jdbc_source_oracle_01 of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 10:03:48,624] INFO [jdbc_source_oracle_01|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = jdbc_source_oracle_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 10:03:48,625] INFO [jdbc_source_oracle_01|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = jdbc_source_oracle_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 10:03:48,625] INFO [jdbc_source_oracle_01|worker] Instantiated connector jdbc_source_oracle_01 with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 10:03:48,625] INFO [jdbc_source_oracle_01|worker] Finished creating connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 10:03:48,625] INFO [jdbc_source_oracle_01|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 10:03:48,626] INFO [jdbc_source_oracle_01|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://192.168.1.2:3306/tai_khoan
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [taikhoan]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:03:48,626] INFO [jdbc_source_oracle_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:03:48,626] INFO [jdbc_source_oracle_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:03:48,626] INFO [jdbc_source_oracle_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:03:48,626] INFO [jdbc_source_oracle_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:03:48,626] INFO [jdbc_source_oracle_01|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 10:03:48,627] INFO [jdbc_source_oracle_01|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:03:58,628] INFO [jdbc_source_oracle_01|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:04:08,629] ERROR [jdbc_source_oracle_01|worker] WorkerConnector{id=jdbc_source_oracle_01} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:04:08,630] ERROR [jdbc_source_oracle_01|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'jdbc_source_oracle_01' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_oracle_01
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector jdbc_source_oracle_01 to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:04:22,445] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://192.168.1.2:3306/tai_khoan
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [taikhoan]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:04:22,446] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:370)
[2024-05-09 10:04:22,450] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_mysql_01 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2024-05-09 10:04:22,450] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:04:22,451] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:04:22,453] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:04:22 +0000] "PUT /connectors/jdbc_source_mysql_01/config HTTP/1.1" 201 505 "-" "PostmanRuntime/7.37.0" 12 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:04:22,462] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=7, memberId='connect-127.0.1.1:8083-10c57917-592c-4c80-b428-82b7a0fbf26a', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:04:22,467] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=7, memberId='connect-127.0.1.1:8083-10c57917-592c-4c80-b428-82b7a0fbf26a', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:04:22,468] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 7 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-10c57917-592c-4c80-b428-82b7a0fbf26a', leaderUrl='http://127.0.1.1:8083/', offset=8, connectorIds=[jdbc_source_mysql_01, jdbc_source_oracle_01], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:04:22,470] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 8 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:04:22,472] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 10:04:22,472] INFO [jdbc_source_mysql_01|worker] Creating connector jdbc_source_mysql_01 of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 10:04:22,472] INFO [jdbc_source_mysql_01|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = jdbc_source_mysql_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 10:04:22,473] INFO [jdbc_source_mysql_01|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = jdbc_source_mysql_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 10:04:22,473] INFO [jdbc_source_mysql_01|worker] Instantiated connector jdbc_source_mysql_01 with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 10:04:22,474] INFO [jdbc_source_mysql_01|worker] Finished creating connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 10:04:22,474] INFO [jdbc_source_mysql_01|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 10:04:22,474] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:04:22,474] INFO [jdbc_source_mysql_01|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://192.168.1.2:3306/tai_khoan
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [taikhoan]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:04:22,474] INFO [jdbc_source_mysql_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:04:22,474] INFO [jdbc_source_mysql_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:04:22,474] INFO [jdbc_source_mysql_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:04:22,475] INFO [jdbc_source_mysql_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:04:22,475] INFO [jdbc_source_mysql_01|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 10:04:22,476] INFO [jdbc_source_mysql_01|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:04:32,477] INFO [jdbc_source_mysql_01|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:04:38,897] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://locahost:3306/tai_khoan
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [taikhoan]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:04:38,898] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:370)
[2024-05-09 10:04:38,903] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_mysql_01 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2024-05-09 10:04:38,903] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Handling connector-only config update by restarting connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2024-05-09 10:04:38,904] INFO [jdbc_source_mysql_01|worker] Stopping connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:04:38,904] INFO [jdbc_source_mysql_01|worker] Scheduled shutdown for WorkerConnector{id=jdbc_source_mysql_01} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2024-05-09 10:04:38,905] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:04:38 +0000] "PUT /connectors/jdbc_source_mysql_01/config HTTP/1.1" 200 502 "-" "PostmanRuntime/7.37.0" 11 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:04:42,478] ERROR [jdbc_source_mysql_01|worker] WorkerConnector{id=jdbc_source_mysql_01} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:04:42,479] ERROR [jdbc_source_mysql_01|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'jdbc_source_mysql_01' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_mysql_01
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector jdbc_source_mysql_01 to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:04:42,480] INFO [jdbc_source_mysql_01|worker] Completed shutdown for WorkerConnector{id=jdbc_source_mysql_01} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2024-05-09 10:04:42,481] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 10:04:42,481] INFO [jdbc_source_mysql_01|worker] Creating connector jdbc_source_mysql_01 of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 10:04:42,482] INFO [jdbc_source_mysql_01|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = jdbc_source_mysql_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 10:04:42,482] INFO [jdbc_source_mysql_01|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = jdbc_source_mysql_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 10:04:42,483] INFO [jdbc_source_mysql_01|worker] Instantiated connector jdbc_source_mysql_01 with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 10:04:42,483] INFO [jdbc_source_mysql_01|worker] Finished creating connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 10:04:42,483] INFO [jdbc_source_mysql_01|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 10:04:42,483] INFO [jdbc_source_mysql_01|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://locahost:3306/tai_khoan
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [taikhoan]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:04:42,484] INFO [jdbc_source_mysql_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:04:42,484] INFO [jdbc_source_mysql_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:04:42,484] INFO [jdbc_source_mysql_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:04:42,484] INFO [jdbc_source_mysql_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:04:42,484] INFO [jdbc_source_mysql_01|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 10:04:42,484] INFO [jdbc_source_mysql_01|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://locahost:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:04:52,486] INFO [jdbc_source_mysql_01|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://locahost:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:05:02,487] ERROR [jdbc_source_mysql_01|worker] WorkerConnector{id=jdbc_source_mysql_01} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://locahost:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://locahost:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:05:02,488] ERROR [jdbc_source_mysql_01|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'jdbc_source_mysql_01' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_mysql_01
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector jdbc_source_mysql_01 to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://locahost:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://locahost:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:06:02,256] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2024-05-09 10:06:02,256] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:348)
[2024-05-09 10:06:02,261] INFO Stopped http_8083@22c0344e{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2024-05-09 10:06:02,261] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2024-05-09 10:06:02,264] INFO Stopped o.e.j.s.ServletContextHandler@3da30ce5{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler:1159)
[2024-05-09 10:06:02,265] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:377)
[2024-05-09 10:06:02,265] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:831)
[2024-05-09 10:06:02,265] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:794)
[2024-05-09 10:06:02,265] INFO [jdbc_source_mysql_01|worker] Stopping connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:06:02,265] INFO [jdbc_source_mysql_01|worker] Scheduled shutdown for WorkerConnector{id=jdbc_source_mysql_01} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2024-05-09 10:06:02,265] INFO [jdbc_source_oracle_01|worker] Stopping connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:06:02,265] INFO [jdbc_source_oracle_01|worker] Scheduled shutdown for WorkerConnector{id=jdbc_source_oracle_01} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2024-05-09 10:06:02,266] INFO [jdbc_source_mysql_01|worker] Completed shutdown for WorkerConnector{id=jdbc_source_mysql_01} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2024-05-09 10:06:02,266] INFO [jdbc_source_oracle_01|worker] Completed shutdown for WorkerConnector{id=jdbc_source_oracle_01} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2024-05-09 10:06:02,266] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Member connect-127.0.1.1:8083-10c57917-592c-4c80-b428-82b7a0fbf26a sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: null) due to the consumer is being closed (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1163)
[2024-05-09 10:06:02,267] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1055)
[2024-05-09 10:06:02,267] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1140)
[2024-05-09 10:06:02,267] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 10:06:02,267] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:06:02,267] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 10:06:02,269] INFO App info kafka.connect for connect-127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 10:06:02,269] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:292)
[2024-05-09 10:06:02,270] INFO [Producer clientId=connect-cluster-statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2024-05-09 10:06:02,273] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 10:06:02,273] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:06:02,273] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:06:02,273] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 10:06:02,274] INFO App info kafka.producer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 10:06:02,275] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2024-05-09 10:06:02,275] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2024-05-09 10:06:02,770] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 10:06:02,770] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:06:02,770] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:06:02,771] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 10:06:02,779] INFO App info kafka.consumer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 10:06:02,779] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2024-05-09 10:06:02,779] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:407)
[2024-05-09 10:06:02,779] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:292)
[2024-05-09 10:06:02,780] INFO [Producer clientId=connect-cluster-configs] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2024-05-09 10:06:02,782] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 10:06:02,782] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:06:02,782] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:06:02,782] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 10:06:02,782] INFO App info kafka.producer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 10:06:02,782] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2024-05-09 10:06:02,782] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2024-05-09 10:06:03,072] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 10:06:03,072] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:06:03,073] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:06:03,073] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 10:06:03,075] INFO App info kafka.consumer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 10:06:03,075] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2024-05-09 10:06:03,075] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:413)
[2024-05-09 10:06:03,075] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:248)
[2024-05-09 10:06:03,076] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:269)
[2024-05-09 10:06:03,076] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:292)
[2024-05-09 10:06:03,076] INFO [Producer clientId=connect-cluster-offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2024-05-09 10:06:03,078] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 10:06:03,079] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:06:03,079] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:06:03,079] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 10:06:03,079] INFO App info kafka.producer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 10:06:03,079] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2024-05-09 10:06:03,079] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2024-05-09 10:06:03,552] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 10:06:03,552] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:06:03,552] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:06:03,552] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 10:06:03,554] INFO App info kafka.consumer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 10:06:03,554] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2024-05-09 10:06:03,554] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:277)
[2024-05-09 10:06:03,554] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 10:06:03,554] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:06:03,554] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 10:06:03,555] INFO App info kafka.connect for 127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 10:06:03,555] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:269)
[2024-05-09 10:06:03,556] INFO App info kafka.admin.client for connect-cluster-shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 10:06:03,557] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 10:06:03,557] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:06:03,557] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 10:06:03,558] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:386)
[2024-05-09 10:06:03,559] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:838)
[2024-05-09 10:06:03,559] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2024-05-09 10:06:07,502] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2024-05-09 10:06:07,506] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/macmkay/kafka/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 17.0.10, 17.0.10+7-Ubuntu-122.04.1
	jvm.classpath = /home/macmkay/kafka/bin/../libs/activation-1.1.1.jar:/home/macmkay/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/macmkay/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/macmkay/kafka/bin/../libs/audience-annotations-0.12.0.jar:/home/macmkay/kafka/bin/../libs/caffeine-2.9.3.jar:/home/macmkay/kafka/bin/../libs/checker-qual-3.19.0.jar:/home/macmkay/kafka/bin/../libs/commons-beanutils-1.9.4.jar:/home/macmkay/kafka/bin/../libs/commons-cli-1.4.jar:/home/macmkay/kafka/bin/../libs/commons-collections-3.2.2.jar:/home/macmkay/kafka/bin/../libs/commons-digester-2.1.jar:/home/macmkay/kafka/bin/../libs/commons-io-2.11.0.jar:/home/macmkay/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/macmkay/kafka/bin/../libs/commons-logging-1.2.jar:/home/macmkay/kafka/bin/../libs/commons-validator-1.7.jar:/home/macmkay/kafka/bin/../libs/connect-api-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-basic-auth-extension-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-json-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-mirror-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-mirror-client-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-runtime-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-transforms-3.7.0.jar:/home/macmkay/kafka/bin/../libs/error_prone_annotations-2.10.0.jar:/home/macmkay/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/macmkay/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/macmkay/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/macmkay/kafka/bin/../libs/jackson-annotations-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-core-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-databind-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-dataformat-csv-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-datatype-jdk8-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-jaxrs-base-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-jaxrs-json-provider-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-module-jaxb-annotations-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-module-scala_2.13-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jakarta.activation-api-1.2.2.jar:/home/macmkay/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/macmkay/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/macmkay/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/macmkay/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/macmkay/kafka/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/home/macmkay/kafka/bin/../libs/javassist-3.29.2-GA.jar:/home/macmkay/kafka/bin/../libs/javax.activation-api-1.2.0.jar:/home/macmkay/kafka/bin/../libs/javax.annotation-api-1.3.2.jar:/home/macmkay/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/macmkay/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/macmkay/kafka/bin/../libs/jaxb-api-2.3.1.jar:/home/macmkay/kafka/bin/../libs/jersey-client-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-common-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-container-servlet-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-hk2-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-server-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jetty-client-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-continuation-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-http-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-io-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-security-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-server-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-servlet-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-servlets-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-util-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-util-ajax-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jline-3.22.0.jar:/home/macmkay/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/macmkay/kafka/bin/../libs/jose4j-0.9.4.jar:/home/macmkay/kafka/bin/../libs/jsr305-3.0.2.jar:/home/macmkay/kafka/bin/../libs/kafka-clients-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-group-coordinator-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-log4j-appender-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-metadata-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-raft-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-server-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-server-common-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-shell-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-storage-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-storage-api-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-streams-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-streams-examples-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-streams-scala_2.13-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-streams-test-utils-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-tools-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-tools-api-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka_2.13-3.7.0.jar:/home/macmkay/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/macmkay/kafka/bin/../libs/maven-artifact-3.8.8.jar:/home/macmkay/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/macmkay/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/macmkay/kafka/bin/../libs/netty-buffer-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-codec-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-common-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-handler-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-resolver-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-transport-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-transport-classes-epoll-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-transport-native-epoll-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-transport-native-unix-common-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/home/macmkay/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/macmkay/kafka/bin/../libs/paranamer-2.8.jar:/home/macmkay/kafka/bin/../libs/pcollections-4.0.1.jar:/home/macmkay/kafka/bin/../libs/plexus-utils-3.3.1.jar:/home/macmkay/kafka/bin/../libs/protobuf-java-3.23.4.jar:/home/macmkay/kafka/bin/../libs/reflections-0.10.2.jar:/home/macmkay/kafka/bin/../libs/reload4j-1.2.25.jar:/home/macmkay/kafka/bin/../libs/rocksdbjni-7.9.2.jar:/home/macmkay/kafka/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/home/macmkay/kafka/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/home/macmkay/kafka/bin/../libs/scala-library-2.13.12.jar:/home/macmkay/kafka/bin/../libs/scala-logging_2.13-3.9.4.jar:/home/macmkay/kafka/bin/../libs/scala-reflect-2.13.12.jar:/home/macmkay/kafka/bin/../libs/slf4j-api-1.7.36.jar:/home/macmkay/kafka/bin/../libs/slf4j-reload4j-1.7.36.jar:/home/macmkay/kafka/bin/../libs/snappy-java-1.1.10.5.jar:/home/macmkay/kafka/bin/../libs/swagger-annotations-2.2.8.jar:/home/macmkay/kafka/bin/../libs/trogdor-3.7.0.jar:/home/macmkay/kafka/bin/../libs/zookeeper-3.8.3.jar:/home/macmkay/kafka/bin/../libs/zookeeper-jute-3.8.3.jar:/home/macmkay/kafka/bin/../libs/zstd-jni-1.5.5-6.jar
	os.spec = Linux, amd64, 5.15.146.1-microsoft-standard-WSL2
	os.vcpus = 12
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2024-05-09 10:06:07,507] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2024-05-09 10:06:07,525] INFO Loading plugin from: /home/macmkay/kafka/./libs/connect-file-3.7.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,675] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/./libs/connect-file-3.7.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,676] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/jtds-1.3.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,683] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/jtds-1.3.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,686] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/slf4j-api-1.7.36.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,694] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/slf4j-api-1.7.36.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,694] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/checker-qual-3.5.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,700] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/checker-qual-3.5.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,700] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/kafka-connect-jdbc-10.7.6.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,708] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/kafka-connect-jdbc-10.7.6.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,709] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ons-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,715] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ons-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,715] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xmlparserv2-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,721] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xmlparserv2-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,721] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/oraclepki-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,729] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/oraclepki-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,729] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/postgresql-42.4.4.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,734] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/postgresql-42.4.4.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,737] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/simplefan-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,742] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/simplefan-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,742] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_cert-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,746] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_cert-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,747] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/sqlite-jdbc-3.41.2.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,750] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/sqlite-jdbc-3.41.2.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,752] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xdb-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,756] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xdb-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,756] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ucp-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,759] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ucp-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,760] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/mssql-jdbc-8.4.1.jre8.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,764] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/mssql-jdbc-8.4.1.jre8.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,854] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_core-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,866] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_core-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,867] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/common-utils-6.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,870] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/common-utils-6.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,870] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ojdbc8-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,874] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ojdbc8-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,901] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/orai18n-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,906] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/orai18n-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,906] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,911] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@1dbd16a6 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,911] INFO Scanning plugins with ServiceLoaderScanner took 387 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2024-05-09 10:06:07,912] INFO Loading plugin from: /home/macmkay/kafka/./libs/connect-file-3.7.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,954] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/./libs/connect-file-3.7.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,954] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/jtds-1.3.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,982] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/jtds-1.3.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,982] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/slf4j-api-1.7.36.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:07,988] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/slf4j-api-1.7.36.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:07,989] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/checker-qual-3.5.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:08,013] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/checker-qual-3.5.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:08,014] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/kafka-connect-jdbc-10.7.6.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:08,038] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/kafka-connect-jdbc-10.7.6.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:08,038] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ons-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:08,049] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ons-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:08,050] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xmlparserv2-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:08,145] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xmlparserv2-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:08,146] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/oraclepki-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:08,166] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/oraclepki-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:08,166] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/postgresql-42.4.4.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:08,213] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/postgresql-42.4.4.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:08,213] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/simplefan-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:08,218] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/simplefan-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:08,218] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_cert-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:08,232] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_cert-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:08,232] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/sqlite-jdbc-3.41.2.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:08,244] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/sqlite-jdbc-3.41.2.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:08,245] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xdb-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:08,257] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xdb-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:08,257] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ucp-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:08,334] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ucp-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:08,334] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/mssql-jdbc-8.4.1.jre8.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:08,400] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/mssql-jdbc-8.4.1.jre8.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:08,408] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_core-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:08,422] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_core-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:08,423] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/common-utils-6.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:08,427] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/common-utils-6.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:08,428] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ojdbc8-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:08,583] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ojdbc8-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:08,583] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/orai18n-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:08,590] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/orai18n-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:08,590] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:06:09,388] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@1dbd16a6 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:06:09,388] INFO Scanning plugins with ReflectionScanner took 1476 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2024-05-09 10:06:09,392] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/kafka-connect-jdbc-10.7.6.jar	io.confluent.connect.jdbc.JdbcSinkConnector	sink	10.7.6
file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/kafka-connect-jdbc-10.7.6.jar	io.confluent.connect.jdbc.JdbcSourceConnector	source	10.7.6
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:122)
[2024-05-09 10:06:09,393] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,393] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,393] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,394] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,394] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,394] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,394] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,394] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,394] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,394] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,394] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,394] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,394] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,394] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,395] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,395] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,395] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,395] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,395] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,395] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,395] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,395] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,395] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,395] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,395] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,395] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,396] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,396] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,396] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,396] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,396] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,396] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,396] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,396] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,396] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,397] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,397] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,397] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,397] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,397] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,397] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,397] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,397] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,398] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,398] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,398] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,398] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,398] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,398] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,398] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,398] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,398] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,399] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:06:09,401] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,401] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,401] INFO Added alias 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,401] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,401] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,402] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,402] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,402] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,402] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,402] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,402] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,402] INFO Added alias 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,402] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,402] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,402] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,402] INFO Added alias 'FileStreamSinkConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,402] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,402] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,403] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,403] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,403] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,403] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,403] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,403] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,403] INFO Added alias 'FileStreamSourceConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,403] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,403] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,403] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,403] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,403] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,403] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,404] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,404] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,404] INFO Added alias 'JdbcSinkConnector' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,404] INFO Added alias 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,404] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,404] INFO Added alias 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,404] INFO Added alias 'JdbcSourceConnector' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,404] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,404] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,404] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,404] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,405] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,405] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,405] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,405] INFO Added alias 'ByteArrayConverter' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,405] INFO Added alias 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,405] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,405] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,405] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,405] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,405] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,405] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,405] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,406] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,406] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:06:09,430] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [./libs/connect-file-3.7.0.jar, ../confluentinc-kafka-connect-jdbc/lib]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = SASL_PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:370)
[2024-05-09 10:06:09,431] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:283)
[2024-05-09 10:06:09,433] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-05-09 10:06:09,482] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin:61)
[2024-05-09 10:06:09,502] INFO These configurations '[producer.sasl.jaas.config, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, status.storage.topic, group.id, plugin.path, consumer.sasl.mechanism, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-05-09 10:06:09,502] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 10:06:09,502] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 10:06:09,502] INFO Kafka startTimeMs: 1715223969502 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 10:06:09,723] INFO Kafka cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.connect.runtime.WorkerConfig:300)
[2024-05-09 10:06:09,724] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 10:06:09,729] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 10:06:09,729] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:06:09,729] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 10:06:09,732] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:370)
[2024-05-09 10:06:09,737] INFO Logging initialized @2566ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2024-05-09 10:06:09,765] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:111)
[2024-05-09 10:06:09,766] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:182)
[2024-05-09 10:06:09,787] INFO jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 17.0.10+7-Ubuntu-122.04.1 (org.eclipse.jetty.server.Server:375)
[2024-05-09 10:06:09,808] INFO Started http_8083@22c0344e{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2024-05-09 10:06:09,808] INFO Started @2638ms (org.eclipse.jetty.server.Server:415)
[2024-05-09 10:06:09,821] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:406)
[2024-05-09 10:06:09,821] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:202)
[2024-05-09 10:06:09,821] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:406)
[2024-05-09 10:06:09,822] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:205)
[2024-05-09 10:06:09,822] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:406)
[2024-05-09 10:06:09,822] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2024-05-09 10:06:09,826] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:370)
[2024-05-09 10:06:09,838] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 10:06:09,838] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 10:06:09,838] INFO Kafka startTimeMs: 1715223969838 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 10:06:09,843] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:370)
[2024-05-09 10:06:09,843] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:370)
[2024-05-09 10:06:09,871] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:406)
[2024-05-09 10:06:09,884] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin:61)
[2024-05-09 10:06:09,898] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 10:06:09,898] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 10:06:09,899] INFO Kafka startTimeMs: 1715223969898 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 10:06:09,901] INFO Kafka Connect worker initialization took 2397ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2024-05-09 10:06:09,901] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2024-05-09 10:06:09,904] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:209)
[2024-05-09 10:06:09,905] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:369)
[2024-05-09 10:06:09,907] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:231)
[2024-05-09 10:06:09,907] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:240)
[2024-05-09 10:06:09,907] INFO Starting KafkaBasedLog with topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2024-05-09 10:06:09,908] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-05-09 10:06:09,912] INFO These configurations '[producer.sasl.jaas.config, group.id, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-05-09 10:06:09,912] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 10:06:09,912] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 10:06:09,912] INFO Kafka startTimeMs: 1715223969912 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 10:06:09,939] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:227)
[2024-05-09 10:06:09,958] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-05-09 10:06:09,968] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2024-05-09 10:06:09,969] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2024-05-09 10:06:09,969] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2024-05-09 10:06:09,977] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 10:06:09,997] INFO These configurations '[producer.sasl.jaas.config, group.id, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-05-09 10:06:09,998] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 10:06:09,998] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 10:06:09,998] INFO Kafka startTimeMs: 1715223969998 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 10:06:10,003] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-05-09 10:06:10,011] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 10:06:10,015] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 10:06:10,046] INFO These configurations '[producer.sasl.jaas.config, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-05-09 10:06:10,046] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 10:06:10,046] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 10:06:10,046] INFO Kafka startTimeMs: 1715223970046 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 10:06:10,055] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 10:06:10,061] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-17, connect-offsets-20, connect-offsets-11, connect-offsets-23, connect-offsets-14, connect-offsets-5, connect-offsets-0, connect-offsets-8, connect-offsets-7, connect-offsets-4, connect-offsets-1, connect-offsets-10, connect-offsets-13, connect-offsets-24, connect-offsets-21, connect-offsets-16, connect-offsets-3, connect-offsets-9, connect-offsets-15, connect-offsets-18, connect-offsets-19, connect-offsets-22, connect-offsets-6, connect-offsets-2, connect-offsets-12 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2024-05-09 10:06:10,063] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,064] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,064] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,064] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,064] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,064] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,064] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,064] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,065] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,065] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,065] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,065] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,065] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,065] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,065] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,065] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,065] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,065] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,065] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,066] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,066] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,066] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,066] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,066] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,066] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,101] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,102] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,102] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,102] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,102] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,102] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,103] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,103] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,103] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,103] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,103] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,103] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,104] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,104] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,104] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,104] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,104] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,105] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,105] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,105] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,105] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,105] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,105] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,105] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,106] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,107] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2024-05-09 10:06:10,107] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2024-05-09 10:06:10,107] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:257)
[2024-05-09 10:06:10,108] INFO Worker started (org.apache.kafka.connect.runtime.Worker:241)
[2024-05-09 10:06:10,109] INFO Starting KafkaBasedLog with topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2024-05-09 10:06:10,116] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-05-09 10:06:10,117] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 10:06:10,123] INFO These configurations '[producer.sasl.jaas.config, group.id, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-05-09 10:06:10,124] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 10:06:10,124] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 10:06:10,124] INFO Kafka startTimeMs: 1715223970124 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 10:06:10,125] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-05-09 10:06:10,126] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 10:06:10,130] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 10:06:10,132] INFO These configurations '[producer.sasl.jaas.config, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-05-09 10:06:10,133] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 10:06:10,133] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 10:06:10,133] INFO Kafka startTimeMs: 1715223970133 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 10:06:10,139] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 10:06:10,140] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-1, connect-status-3, connect-status-2, connect-status-0, connect-status-4 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2024-05-09 10:06:10,141] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,141] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,141] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,141] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,141] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,152] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,153] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,153] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,153] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,153] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,198] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2024-05-09 10:06:10,199] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2024-05-09 10:06:10,201] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:378)
[2024-05-09 10:06:10,201] INFO Starting KafkaBasedLog with topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2024-05-09 10:06:10,211] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-05-09 10:06:10,212] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 10:06:10,218] INFO These configurations '[producer.sasl.jaas.config, group.id, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-05-09 10:06:10,219] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 10:06:10,219] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 10:06:10,219] INFO Kafka startTimeMs: 1715223970218 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 10:06:10,219] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-05-09 10:06:10,220] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 10:06:10,225] INFO These configurations '[producer.sasl.jaas.config, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-05-09 10:06:10,225] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 10:06:10,225] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 10:06:10,225] INFO Kafka startTimeMs: 1715223970225 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 10:06:10,226] INFO [Producer clientId=connect-cluster-configs] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 10:06:10,232] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 10:06:10,233] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2024-05-09 10:06:10,233] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:06:10,243] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:06:10,250] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2024-05-09 10:06:10,250] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2024-05-09 10:06:10,250] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:402)
[2024-05-09 10:06:10,250] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:376)
[2024-05-09 10:06:10,262] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 10:06:10,263] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2024-05-09 10:06:10,267] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:06:10,267] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:06:10,280] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:06:10,401] INFO Started o.e.j.s.ServletContextHandler@19542115{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2024-05-09 10:06:10,401] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:302)
[2024-05-09 10:06:10,401] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2024-05-09 10:06:13,285] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=9, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:06:13,308] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=9, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:06:13,309] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 9 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', leaderUrl='http://127.0.1.1:8083/', offset=9, connectorIds=[jdbc_source_mysql_01, jdbc_source_oracle_01], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:06:13,310] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1753)
[2024-05-09 10:06:13,310] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Current config state offset -1 is behind group assignment 9, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1826)
[2024-05-09 10:06:13,313] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 9 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1853)
[2024-05-09 10:06:13,313] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 9 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:06:13,314] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 10:06:13,314] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 10:06:13,317] INFO [jdbc_source_oracle_01|worker] Creating connector jdbc_source_oracle_01 of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 10:06:13,317] INFO [jdbc_source_mysql_01|worker] Creating connector jdbc_source_mysql_01 of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 10:06:13,320] INFO [jdbc_source_mysql_01|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = jdbc_source_mysql_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 10:06:13,320] INFO [jdbc_source_oracle_01|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = jdbc_source_oracle_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 10:06:13,322] INFO [jdbc_source_mysql_01|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = jdbc_source_mysql_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 10:06:13,322] INFO [jdbc_source_oracle_01|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = jdbc_source_oracle_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 10:06:13,328] INFO [jdbc_source_mysql_01|worker] Instantiated connector jdbc_source_mysql_01 with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 10:06:13,328] INFO [jdbc_source_mysql_01|worker] Finished creating connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 10:06:13,329] INFO [jdbc_source_oracle_01|worker] Instantiated connector jdbc_source_oracle_01 with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 10:06:13,329] INFO [jdbc_source_oracle_01|worker] Finished creating connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 10:06:13,329] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:06:13,329] INFO [jdbc_source_mysql_01|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 10:06:13,329] INFO [jdbc_source_oracle_01|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 10:06:13,341] INFO [jdbc_source_mysql_01|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://locahost:3306/tai_khoan
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [taikhoan]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:06:13,341] INFO [jdbc_source_oracle_01|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://192.168.1.2:3306/tai_khoan
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [taikhoan]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:06:13,341] INFO [jdbc_source_oracle_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:06:13,341] INFO [jdbc_source_mysql_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:06:13,341] INFO [jdbc_source_mysql_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:06:13,341] INFO [jdbc_source_oracle_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:06:13,343] INFO [jdbc_source_mysql_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:06:13,343] INFO [jdbc_source_mysql_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:06:13,343] INFO [jdbc_source_oracle_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:06:13,344] INFO [jdbc_source_oracle_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:06:13,345] INFO [jdbc_source_mysql_01|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 10:06:13,345] INFO [jdbc_source_oracle_01|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 10:06:13,346] INFO [jdbc_source_mysql_01|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://locahost:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:06:13,346] INFO [jdbc_source_oracle_01|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:06:23,349] INFO [jdbc_source_mysql_01|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://locahost:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:06:23,349] INFO [jdbc_source_oracle_01|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:06:33,351] ERROR [jdbc_source_mysql_01|worker] WorkerConnector{id=jdbc_source_mysql_01} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://locahost:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://locahost:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:06:33,351] ERROR [jdbc_source_oracle_01|worker] WorkerConnector{id=jdbc_source_oracle_01} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:06:33,367] ERROR [jdbc_source_mysql_01|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'jdbc_source_mysql_01' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_mysql_01
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector jdbc_source_mysql_01 to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://locahost:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://locahost:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:06:33,367] ERROR [jdbc_source_oracle_01|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'jdbc_source_oracle_01' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_oracle_01
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector jdbc_source_oracle_01 to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:07:38,810] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://127.0.0.1:3306/ho_so?createDatabaseIfNotExist=true
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [taikhoan]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:07:38,820] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:370)
[2024-05-09 10:07:38,918] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_mysql_01 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2024-05-09 10:07:38,922] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Handling connector-only config update by restarting connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2024-05-09 10:07:38,925] INFO [jdbc_source_mysql_01|worker] Stopping connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:07:38,926] INFO [jdbc_source_mysql_01|worker] Scheduled shutdown for WorkerConnector{id=jdbc_source_mysql_01} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2024-05-09 10:07:38,933] INFO [jdbc_source_mysql_01|worker] Completed shutdown for WorkerConnector{id=jdbc_source_mysql_01} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2024-05-09 10:07:38,951] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 10:07:38,952] INFO [jdbc_source_mysql_01|worker] Creating connector jdbc_source_mysql_01 of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 10:07:38,957] INFO [jdbc_source_mysql_01|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = jdbc_source_mysql_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 10:07:38,958] INFO [jdbc_source_mysql_01|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = jdbc_source_mysql_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 10:07:38,960] INFO [jdbc_source_mysql_01|worker] Instantiated connector jdbc_source_mysql_01 with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 10:07:38,960] INFO [jdbc_source_mysql_01|worker] Finished creating connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 10:07:38,961] INFO [jdbc_source_mysql_01|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 10:07:38,962] INFO [jdbc_source_mysql_01|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://127.0.0.1:3306/ho_so?createDatabaseIfNotExist=true
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [taikhoan]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:07:38,962] INFO [jdbc_source_mysql_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:07:38,963] INFO [jdbc_source_mysql_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:07:38,964] INFO [jdbc_source_mysql_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:07:38,965] INFO [jdbc_source_mysql_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:07:38,967] INFO [jdbc_source_mysql_01|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 10:07:38,975] INFO [jdbc_source_mysql_01|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://127.0.0.1:3306/ho_so?createDatabaseIfNotExist=true
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:07:39,080] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:07:38 +0000] "PUT /connectors/jdbc_source_mysql_01/config HTTP/1.1" 200 529 "-" "PostmanRuntime/7.37.0" 616 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:07:48,979] INFO [jdbc_source_mysql_01|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://127.0.0.1:3306/ho_so?createDatabaseIfNotExist=true
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:07:58,981] ERROR [jdbc_source_mysql_01|worker] WorkerConnector{id=jdbc_source_mysql_01} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://127.0.0.1:3306/ho_so?createDatabaseIfNotExist=true
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://127.0.0.1:3306/ho_so?createDatabaseIfNotExist=true
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:07:58,984] ERROR [jdbc_source_mysql_01|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'jdbc_source_mysql_01' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_mysql_01
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector jdbc_source_mysql_01 to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://127.0.0.1:3306/ho_so?createDatabaseIfNotExist=true
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://127.0.0.1:3306/ho_so?createDatabaseIfNotExist=true
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:08:03,575] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/ho_so?createDatabaseIfNotExist=true
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [taikhoan]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:08:03,576] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:370)
[2024-05-09 10:08:03,592] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_mysql_01 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2024-05-09 10:08:03,592] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Handling connector-only config update by restarting connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2024-05-09 10:08:03,593] INFO [jdbc_source_mysql_01|worker] Stopping connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:08:03,593] INFO [jdbc_source_mysql_01|worker] Scheduled shutdown for WorkerConnector{id=jdbc_source_mysql_01} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2024-05-09 10:08:03,594] INFO [jdbc_source_mysql_01|worker] Completed shutdown for WorkerConnector{id=jdbc_source_mysql_01} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2024-05-09 10:08:03,596] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 10:08:03,596] INFO [jdbc_source_mysql_01|worker] Creating connector jdbc_source_mysql_01 of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 10:08:03,597] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:08:03 +0000] "PUT /connectors/jdbc_source_mysql_01/config HTTP/1.1" 200 529 "-" "PostmanRuntime/7.37.0" 40 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:08:03,598] INFO [jdbc_source_mysql_01|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = jdbc_source_mysql_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 10:08:03,600] INFO [jdbc_source_mysql_01|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = jdbc_source_mysql_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 10:08:03,601] INFO [jdbc_source_mysql_01|worker] Instantiated connector jdbc_source_mysql_01 with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 10:08:03,602] INFO [jdbc_source_mysql_01|worker] Finished creating connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 10:08:03,602] INFO [jdbc_source_mysql_01|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 10:08:03,602] INFO [jdbc_source_mysql_01|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/ho_so?createDatabaseIfNotExist=true
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [taikhoan]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:08:03,602] INFO [jdbc_source_mysql_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:08:03,602] INFO [jdbc_source_mysql_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:08:03,603] INFO [jdbc_source_mysql_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:08:03,603] INFO [jdbc_source_mysql_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:08:03,603] INFO [jdbc_source_mysql_01|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 10:08:03,605] INFO [jdbc_source_mysql_01|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/ho_so?createDatabaseIfNotExist=true
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:08:13,607] INFO [jdbc_source_mysql_01|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/ho_so?createDatabaseIfNotExist=true
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:08:14,807] INFO 127.0.0.1 - - [09/May/2024:03:08:14 +0000] "GET /connectors HTTP/1.1" 200 48 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 8 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:08:14,819] INFO 127.0.0.1 - - [09/May/2024:03:08:14 +0000] "GET /connectors/jdbc_source_mysql_01 HTTP/1.1" 200 529 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 6 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:08:14,832] INFO 127.0.0.1 - - [09/May/2024:03:08:14 +0000] "GET /connectors/jdbc_source_mysql_01/status HTTP/1.1" 200 122 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 10 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:08:14,837] INFO 127.0.0.1 - - [09/May/2024:03:08:14 +0000] "GET /connectors/jdbc_source_oracle_01 HTTP/1.1" 200 507 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:08:14,840] INFO 127.0.0.1 - - [09/May/2024:03:08:14 +0000] "GET /connectors/jdbc_source_oracle_01/status HTTP/1.1" 200 2118 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:08:23,609] ERROR [jdbc_source_mysql_01|worker] WorkerConnector{id=jdbc_source_mysql_01} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/ho_so?createDatabaseIfNotExist=true
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/ho_so?createDatabaseIfNotExist=true
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:08:23,610] ERROR [jdbc_source_mysql_01|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'jdbc_source_mysql_01' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_mysql_01
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector jdbc_source_mysql_01 to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/ho_so?createDatabaseIfNotExist=true
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/ho_so?createDatabaseIfNotExist=true
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:08:29,557] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/ho_so?createDatabaseIfNotExist=true
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [taikhoan]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:08:29,558] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:370)
[2024-05-09 10:08:29,564] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_mysql_01 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2024-05-09 10:08:29,564] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Handling connector-only config update by restarting connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2024-05-09 10:08:29,565] INFO [jdbc_source_mysql_01|worker] Stopping connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:08:29,565] INFO [jdbc_source_mysql_01|worker] Scheduled shutdown for WorkerConnector{id=jdbc_source_mysql_01} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2024-05-09 10:08:29,565] INFO [jdbc_source_mysql_01|worker] Completed shutdown for WorkerConnector{id=jdbc_source_mysql_01} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2024-05-09 10:08:29,566] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:08:29 +0000] "PUT /connectors/jdbc_source_mysql_01/config HTTP/1.1" 200 529 "-" "PostmanRuntime/7.37.0" 13 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:08:29,567] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 10:08:29,567] INFO [jdbc_source_mysql_01|worker] Creating connector jdbc_source_mysql_01 of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 10:08:29,569] INFO [jdbc_source_mysql_01|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = jdbc_source_mysql_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 10:08:29,569] INFO [jdbc_source_mysql_01|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = jdbc_source_mysql_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 10:08:29,570] INFO [jdbc_source_mysql_01|worker] Instantiated connector jdbc_source_mysql_01 with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 10:08:29,570] INFO [jdbc_source_mysql_01|worker] Finished creating connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 10:08:29,571] INFO [jdbc_source_mysql_01|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 10:08:29,571] INFO [jdbc_source_mysql_01|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/ho_so?createDatabaseIfNotExist=true
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [taikhoan]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:08:29,571] INFO [jdbc_source_mysql_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:08:29,571] INFO [jdbc_source_mysql_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:08:29,571] INFO [jdbc_source_mysql_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:08:29,571] INFO [jdbc_source_mysql_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:08:29,572] INFO [jdbc_source_mysql_01|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 10:08:29,572] INFO [jdbc_source_mysql_01|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/ho_so?createDatabaseIfNotExist=true
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:08:39,574] INFO [jdbc_source_mysql_01|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/ho_so?createDatabaseIfNotExist=true
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:08:49,576] ERROR [jdbc_source_mysql_01|worker] WorkerConnector{id=jdbc_source_mysql_01} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/ho_so?createDatabaseIfNotExist=true
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/ho_so?createDatabaseIfNotExist=true
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:08:49,577] ERROR [jdbc_source_mysql_01|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'jdbc_source_mysql_01' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_mysql_01
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector jdbc_source_mysql_01 to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/ho_so?createDatabaseIfNotExist=true
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/ho_so?createDatabaseIfNotExist=true
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:08:50,507] INFO 127.0.0.1 - - [09/May/2024:03:08:50 +0000] "DELETE /connectors/JDBC_SOURCE_MYSQL_01 HTTP/1.1" 404 71 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 10 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:09:02,658] INFO 127.0.0.1 - - [09/May/2024:03:09:02 +0000] "DELETE /connectors/JDBC_SOURCE_ORACLE_01 HTTP/1.1" 404 72 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:09:27,264] ERROR Uncaught exception in REST call to /connectors/jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
javax.ws.rs.NotAllowedException: HTTP 405 Method Not Allowed
	at org.glassfish.jersey.server.internal.routing.MethodSelectingRouter.getMethodRouter(MethodSelectingRouter.java:408)
	at org.glassfish.jersey.server.internal.routing.MethodSelectingRouter.access$000(MethodSelectingRouter.java:73)
	at org.glassfish.jersey.server.internal.routing.MethodSelectingRouter$4.apply(MethodSelectingRouter.java:673)
	at org.glassfish.jersey.server.internal.routing.MethodSelectingRouter.apply(MethodSelectingRouter.java:304)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:86)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:69)
	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:38)
	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:09:27,271] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:09:27 +0000] "POST /connectors/jdbc_source_mysql_01 HTTP/1.1" 405 58 "-" "PostmanRuntime/7.37.0" 9 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:09:32,175] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:09:32 +0000] "GET /connectors/jdbc_source_mysql_01 HTTP/1.1" 200 529 "-" "PostmanRuntime/7.37.0" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:09:38,585] INFO 127.0.0.1 - - [09/May/2024:03:09:38 +0000] "GET /connectors HTTP/1.1" 200 48 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:09:38,588] INFO 127.0.0.1 - - [09/May/2024:03:09:38 +0000] "GET /connectors/jdbc_source_mysql_01 HTTP/1.1" 200 529 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:09:38,591] INFO 127.0.0.1 - - [09/May/2024:03:09:38 +0000] "GET /connectors/jdbc_source_mysql_01/status HTTP/1.1" 200 2165 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:09:38,595] INFO 127.0.0.1 - - [09/May/2024:03:09:38 +0000] "GET /connectors/jdbc_source_oracle_01 HTTP/1.1" 200 507 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:09:38,599] INFO 127.0.0.1 - - [09/May/2024:03:09:38 +0000] "GET /connectors/jdbc_source_oracle_01/status HTTP/1.1" 200 2118 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:09:53,545] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2442)
[2024-05-09 10:10:07,261] INFO 127.0.0.1 - - [09/May/2024:03:10:07 +0000] "GET /connectors HTTP/1.1" 200 48 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:10:07,265] INFO 127.0.0.1 - - [09/May/2024:03:10:07 +0000] "GET /connectors/jdbc_source_mysql_01 HTTP/1.1" 200 529 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:10:07,268] INFO 127.0.0.1 - - [09/May/2024:03:10:07 +0000] "GET /connectors/jdbc_source_mysql_01/status HTTP/1.1" 200 2165 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 1 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:10:07,270] INFO 127.0.0.1 - - [09/May/2024:03:10:07 +0000] "GET /connectors/jdbc_source_oracle_01 HTTP/1.1" 200 507 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 1 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:10:07,274] INFO 127.0.0.1 - - [09/May/2024:03:10:07 +0000] "GET /connectors/jdbc_source_oracle_01/status HTTP/1.1" 200 2118 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:10:13,848] INFO 127.0.0.1 - - [09/May/2024:03:10:13 +0000] "DELETE /connectors/JDBC_SOURCE_MYSQL_01 HTTP/1.1" 404 71 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:10:30,098] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:10:30 +0000] "GET /connectors/jdbc_source_mysql_02 HTTP/1.1" 404 71 "-" "PostmanRuntime/7.37.0" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:10:34,117] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:10:34 +0000] "GET /connectors/jdbc_source_mysql_01 HTTP/1.1" 200 529 "-" "PostmanRuntime/7.37.0" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:10:43,936] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:10:43 +0000] "GET /connectors/jdbc_source_mysql_01/status HTTP/1.1" 200 2165 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36 Edg/124.0.0.0" 8 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:10:55,243] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:10:55 +0000] "GET /connectors/jdbc_source_oracle_01/status HTTP/1.1" 200 2118 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36 Edg/124.0.0.0" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:10:59,448] INFO 127.0.0.1 - - [09/May/2024:03:10:59 +0000] "DELETE /connectors/JDBC_SOURCE_MYSQL_01 HTTP/1.1" 404 71 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:11:01,906] INFO 127.0.0.1 - - [09/May/2024:03:11:01 +0000] "GET /connectors HTTP/1.1" 200 48 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:11:01,909] INFO 127.0.0.1 - - [09/May/2024:03:11:01 +0000] "GET /connectors/jdbc_source_mysql_01 HTTP/1.1" 200 529 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:11:01,913] INFO 127.0.0.1 - - [09/May/2024:03:11:01 +0000] "GET /connectors/jdbc_source_mysql_01/status HTTP/1.1" 200 2165 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:11:01,918] INFO 127.0.0.1 - - [09/May/2024:03:11:01 +0000] "GET /connectors/jdbc_source_oracle_01 HTTP/1.1" 200 507 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:11:01,921] INFO 127.0.0.1 - - [09/May/2024:03:11:01 +0000] "GET /connectors/jdbc_source_oracle_01/status HTTP/1.1" 200 2118 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:11:03,829] INFO 127.0.0.1 - - [09/May/2024:03:11:03 +0000] "DELETE /connectors/JDBC_SOURCE_MYSQL_01 HTTP/1.1" 404 71 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:11:09,923] INFO [AdminClient clientId=connect-cluster-shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:11:37,250] INFO 127.0.0.1 - - [09/May/2024:03:11:37 +0000] "GET /connectors HTTP/1.1" 200 48 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:11:37,253] INFO 127.0.0.1 - - [09/May/2024:03:11:37 +0000] "GET /connectors/jdbc_source_mysql_01 HTTP/1.1" 200 529 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:11:37,256] INFO 127.0.0.1 - - [09/May/2024:03:11:37 +0000] "GET /connectors/jdbc_source_mysql_01/status HTTP/1.1" 200 2165 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:11:37,259] INFO 127.0.0.1 - - [09/May/2024:03:11:37 +0000] "GET /connectors/jdbc_source_oracle_01 HTTP/1.1" 200 507 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:11:37,261] INFO 127.0.0.1 - - [09/May/2024:03:11:37 +0000] "GET /connectors/jdbc_source_oracle_01/status HTTP/1.1" 200 2118 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 1 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:12:10,902] INFO 127.0.0.1 - - [09/May/2024:03:12:10 +0000] "GET /connectors HTTP/1.1" 200 48 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:12:10,948] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://mysql:3306/football
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [players]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = 
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:12:10,967] INFO 127.0.0.1 - - [09/May/2024:03:12:10 +0000] "PUT /connector-plugins/io.confluent.connect.jdbc.JdbcSourceConnector/config/validate HTTP/1.1" 200 37909 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 29 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:12:11,019] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://mysql:3306/football
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [players]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = 
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:12:11,020] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:370)
[2024-05-09 10:12:11,026] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector MYSQL_SOURCE_CONNECTOR config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2024-05-09 10:12:11,026] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:12:11,026] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:12:11,029] INFO 127.0.0.1 - - [09/May/2024:03:12:10 +0000] "POST /connectors HTTP/1.1" 201 863 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 37 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:12:11,034] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=10, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:12:11,046] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=10, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:12:11,047] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 10 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', leaderUrl='http://127.0.1.1:8083/', offset=14, connectorIds=[MYSQL_SOURCE_CONNECTOR, jdbc_source_mysql_01, jdbc_source_oracle_01], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:12:11,047] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 14 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:12:11,048] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector MYSQL_SOURCE_CONNECTOR (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 10:12:11,048] INFO [MYSQL_SOURCE_CONNECTOR|worker] Creating connector MYSQL_SOURCE_CONNECTOR of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 10:12:11,049] INFO [MYSQL_SOURCE_CONNECTOR|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = MYSQL_SOURCE_CONNECTOR
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [ksqlCreateKey, ksqlExtractString]
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 10:12:11,050] INFO [MYSQL_SOURCE_CONNECTOR|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = MYSQL_SOURCE_CONNECTOR
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [ksqlCreateKey, ksqlExtractString]
	transforms.ksqlCreateKey.fields = [id]
	transforms.ksqlCreateKey.negate = false
	transforms.ksqlCreateKey.predicate = null
	transforms.ksqlCreateKey.type = class org.apache.kafka.connect.transforms.ValueToKey
	transforms.ksqlExtractString.field = id
	transforms.ksqlExtractString.negate = false
	transforms.ksqlExtractString.predicate = null
	transforms.ksqlExtractString.type = class org.apache.kafka.connect.transforms.ExtractField$Key
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 10:12:11,050] INFO [MYSQL_SOURCE_CONNECTOR|worker] Instantiated connector MYSQL_SOURCE_CONNECTOR with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 10:12:11,051] INFO [MYSQL_SOURCE_CONNECTOR|worker] Finished creating connector MYSQL_SOURCE_CONNECTOR (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 10:12:11,051] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:12:11,051] INFO [MYSQL_SOURCE_CONNECTOR|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 10:12:11,051] INFO [MYSQL_SOURCE_CONNECTOR|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://mysql:3306/football
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [players]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = 
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:12:11,052] INFO [MYSQL_SOURCE_CONNECTOR|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:12:11,052] INFO [MYSQL_SOURCE_CONNECTOR|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:12:11,052] INFO [MYSQL_SOURCE_CONNECTOR|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:12:11,052] INFO [MYSQL_SOURCE_CONNECTOR|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:12:11,052] INFO [MYSQL_SOURCE_CONNECTOR|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 10:12:11,053] INFO [MYSQL_SOURCE_CONNECTOR|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://mysql:3306/football
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:12:19,872] INFO 127.0.0.1 - - [09/May/2024:03:12:19 +0000] "GET /connectors HTTP/1.1" 200 73 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:12:19,875] INFO 127.0.0.1 - - [09/May/2024:03:12:19 +0000] "GET /connectors/jdbc_source_mysql_01 HTTP/1.1" 200 529 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:12:19,878] INFO 127.0.0.1 - - [09/May/2024:03:12:19 +0000] "GET /connectors/jdbc_source_mysql_01/status HTTP/1.1" 200 2165 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 1 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:12:19,880] INFO 127.0.0.1 - - [09/May/2024:03:12:19 +0000] "GET /connectors/jdbc_source_oracle_01 HTTP/1.1" 200 507 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 1 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:12:19,882] INFO 127.0.0.1 - - [09/May/2024:03:12:19 +0000] "GET /connectors/jdbc_source_oracle_01/status HTTP/1.1" 200 2118 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 1 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:12:19,885] INFO 127.0.0.1 - - [09/May/2024:03:12:19 +0000] "GET /connectors/MYSQL_SOURCE_CONNECTOR HTTP/1.1" 200 863 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:12:19,888] INFO 127.0.0.1 - - [09/May/2024:03:12:19 +0000] "GET /connectors/MYSQL_SOURCE_CONNECTOR/status HTTP/1.1" 404 83 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:12:21,054] INFO [MYSQL_SOURCE_CONNECTOR|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://mysql:3306/football
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:12:28,432] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:12:28 +0000] "GET /connectors/MYSQL_SOURCE_CONNECTOR/status HTTP/1.1" 404 83 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36 Edg/124.0.0.0" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:12:31,056] ERROR [MYSQL_SOURCE_CONNECTOR|worker] WorkerConnector{id=MYSQL_SOURCE_CONNECTOR} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://mysql:3306/football
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://mysql:3306/football
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:12:31,057] ERROR [MYSQL_SOURCE_CONNECTOR|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'MYSQL_SOURCE_CONNECTOR' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: MYSQL_SOURCE_CONNECTOR
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector MYSQL_SOURCE_CONNECTOR to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://mysql:3306/football
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://mysql:3306/football
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:12:31,935] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:12:31 +0000] "GET /connectors/MYSQL_SOURCE_CONNECTOR HTTP/1.1" 200 863 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36 Edg/124.0.0.0" 4 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:12:36,720] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:12:36 +0000] "GET /connectors/MYSQL_SOURCE_CONNECTOR/status HTTP/1.1" 200 2105 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36 Edg/124.0.0.0" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:12:40,375] INFO 127.0.0.1 - - [09/May/2024:03:12:40 +0000] "GET /connectors HTTP/1.1" 200 73 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:12:40,378] INFO 127.0.0.1 - - [09/May/2024:03:12:40 +0000] "GET /connectors/jdbc_source_mysql_01 HTTP/1.1" 200 529 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:12:40,382] INFO 127.0.0.1 - - [09/May/2024:03:12:40 +0000] "GET /connectors/jdbc_source_mysql_01/status HTTP/1.1" 200 2165 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:12:40,384] INFO 127.0.0.1 - - [09/May/2024:03:12:40 +0000] "GET /connectors/jdbc_source_oracle_01 HTTP/1.1" 200 507 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 1 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:12:40,387] INFO 127.0.0.1 - - [09/May/2024:03:12:40 +0000] "GET /connectors/jdbc_source_oracle_01/status HTTP/1.1" 200 2118 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:12:40,389] INFO 127.0.0.1 - - [09/May/2024:03:12:40 +0000] "GET /connectors/MYSQL_SOURCE_CONNECTOR HTTP/1.1" 200 863 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 1 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:12:40,392] INFO 127.0.0.1 - - [09/May/2024:03:12:40 +0000] "GET /connectors/MYSQL_SOURCE_CONNECTOR/status HTTP/1.1" 200 2105 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:13:17,588] INFO Successfully processed removal of connector 'MYSQL_SOURCE_CONNECTOR' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1011)
[2024-05-09 10:13:17,588] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector MYSQL_SOURCE_CONNECTOR config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2024-05-09 10:13:17,589] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector MYSQL_SOURCE_CONNECTOR (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2024-05-09 10:13:17,589] INFO [MYSQL_SOURCE_CONNECTOR|worker] Stopping connector MYSQL_SOURCE_CONNECTOR (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:13:17,589] INFO [MYSQL_SOURCE_CONNECTOR|worker] Scheduled shutdown for WorkerConnector{id=MYSQL_SOURCE_CONNECTOR} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2024-05-09 10:13:17,589] INFO [MYSQL_SOURCE_CONNECTOR|worker] Completed shutdown for WorkerConnector{id=MYSQL_SOURCE_CONNECTOR} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2024-05-09 10:13:17,589] INFO 127.0.0.1 - - [09/May/2024:03:13:17 +0000] "DELETE /connectors/MYSQL_SOURCE_CONNECTOR HTTP/1.1" 204 0 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:13:17,590] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:13:17,590] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:13:17,592] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=11, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:13:17,595] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=11, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:13:17,646] INFO [MYSQL_SOURCE_CONNECTOR|worker] Stopping connector MYSQL_SOURCE_CONNECTOR (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:13:17,646] WARN [MYSQL_SOURCE_CONNECTOR|worker] Ignoring stop request for unowned connector MYSQL_SOURCE_CONNECTOR (org.apache.kafka.connect.runtime.Worker:423)
[2024-05-09 10:13:17,647] WARN [MYSQL_SOURCE_CONNECTOR|worker] Ignoring await stop request for non-present connector MYSQL_SOURCE_CONNECTOR (org.apache.kafka.connect.runtime.Worker:444)
[2024-05-09 10:13:17,647] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2024-05-09 10:13:17,649] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2024-05-09 10:13:17,649] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 11 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', leaderUrl='http://127.0.1.1:8083/', offset=16, connectorIds=[jdbc_source_mysql_01, jdbc_source_oracle_01], taskIds=[], revokedConnectorIds=[MYSQL_SOURCE_CONNECTOR], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:13:17,649] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 16 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:13:17,649] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:13:17,649] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:13:17,649] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:13:17,651] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=12, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:13:17,655] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=12, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:13:17,655] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 12 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', leaderUrl='http://127.0.1.1:8083/', offset=16, connectorIds=[jdbc_source_mysql_01, jdbc_source_oracle_01], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:13:17,655] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 16 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:13:17,655] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:13:25,884] INFO 127.0.0.1 - - [09/May/2024:03:13:25 +0000] "DELETE /connectors/JDBC_SOURCE_MYSQL_01 HTTP/1.1" 404 71 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:13:42,710] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:13:42 +0000] "GET /connectors/jdbc_source_oracle_01/status HTTP/1.1" 200 2118 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36 Edg/124.0.0.0" 4 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:13:44,811] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:13:44 +0000] "GET /connectors/jdbc_source_oracle_01/status HTTP/1.1" 200 2118 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36 Edg/124.0.0.0" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:13:51,636] INFO 127.0.0.1 - - [09/May/2024:03:13:51 +0000] "DELETE /connectors/JDBC_SOURCE_MYSQL_01 HTTP/1.1" 404 71 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:14:03,112] INFO 127.0.0.1 - - [09/May/2024:03:14:03 +0000] "DELETE /connectors/JDBC_SOURCE_ORACLE_01 HTTP/1.1" 404 72 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:14:47,203] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:14:47 +0000] "GET /connectors/jdbc_source_mysql_01 HTTP/1.1" 200 529 "-" "PostmanRuntime/7.37.0" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:14:48,139] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:14:48 +0000] "GET /connectors/jdbc_source_mysql_01 HTTP/1.1" 200 529 "-" "PostmanRuntime/7.37.0" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:15:10,234] INFO [Producer clientId=connect-cluster-offsets] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:15:10,274] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:15:10,341] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:15:10,394] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:15:10,444] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:15:15,372] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:15:15 +0000] "GET /connectors/jdbc_source_mysql_01 HTTP/1.1" 200 529 "-" "PostmanRuntime/7.37.0" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:15:16,189] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:15:16 +0000] "GET /connectors/jdbc_source_mysql_01 HTTP/1.1" 200 529 "-" "PostmanRuntime/7.37.0" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:15:17,674] INFO [Producer clientId=connect-cluster-configs] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:15:17,757] INFO [Producer clientId=connect-cluster-statuses] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:15:27,398] ERROR Uncaught exception in REST call to /connectors/jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
javax.ws.rs.NotAllowedException: HTTP 405 Method Not Allowed
	at org.glassfish.jersey.server.internal.routing.MethodSelectingRouter.getMethodRouter(MethodSelectingRouter.java:408)
	at org.glassfish.jersey.server.internal.routing.MethodSelectingRouter.access$000(MethodSelectingRouter.java:73)
	at org.glassfish.jersey.server.internal.routing.MethodSelectingRouter$4.apply(MethodSelectingRouter.java:673)
	at org.glassfish.jersey.server.internal.routing.MethodSelectingRouter.apply(MethodSelectingRouter.java:304)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:86)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:69)
	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:38)
	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:15:27,400] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:15:27 +0000] "PUT /connectors/jdbc_source_mysql_01 HTTP/1.1" 405 58 "-" "PostmanRuntime/7.37.0" 4 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:15:28,995] ERROR Uncaught exception in REST call to /connectors/jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
javax.ws.rs.NotAllowedException: HTTP 405 Method Not Allowed
	at org.glassfish.jersey.server.internal.routing.MethodSelectingRouter.getMethodRouter(MethodSelectingRouter.java:408)
	at org.glassfish.jersey.server.internal.routing.MethodSelectingRouter.access$000(MethodSelectingRouter.java:73)
	at org.glassfish.jersey.server.internal.routing.MethodSelectingRouter$4.apply(MethodSelectingRouter.java:673)
	at org.glassfish.jersey.server.internal.routing.MethodSelectingRouter.apply(MethodSelectingRouter.java:304)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:86)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:69)
	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:38)
	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:15:28,998] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:15:28 +0000] "PUT /connectors/jdbc_source_mysql_01 HTTP/1.1" 405 58 "-" "PostmanRuntime/7.37.0" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:15:31,862] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:15:31 +0000] "GET /connectors/jdbc_source_mysql_01 HTTP/1.1" 200 529 "-" "PostmanRuntime/7.37.0" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:15:34,848] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:15:34 +0000] "GET /connectors/jdbc_source_mysql_01 HTTP/1.1" 200 529 "-" "PostmanRuntime/7.37.0" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:15:57,571] INFO 127.0.0.1 - - [09/May/2024:03:15:57 +0000] "GET /connectors HTTP/1.1" 200 48 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:15:57,573] INFO 127.0.0.1 - - [09/May/2024:03:15:57 +0000] "GET /connectors/jdbc_source_mysql_01 HTTP/1.1" 200 529 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 1 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:15:57,575] INFO 127.0.0.1 - - [09/May/2024:03:15:57 +0000] "GET /connectors/jdbc_source_mysql_01/status HTTP/1.1" 200 2165 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 1 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:15:57,578] INFO 127.0.0.1 - - [09/May/2024:03:15:57 +0000] "GET /connectors/jdbc_source_oracle_01 HTTP/1.1" 200 507 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:15:57,580] INFO 127.0.0.1 - - [09/May/2024:03:15:57 +0000] "GET /connectors/jdbc_source_oracle_01/status HTTP/1.1" 200 2118 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 1 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:16:24,174] INFO 127.0.0.1 - - [09/May/2024:03:16:24 +0000] "DELETE /connectors/JDBC_SOURCE_MYSQL_01 HTTP/1.1" 404 71 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:17:05,832] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:17:05 +0000] "GET /connectors HTTP/1.1" 200 48 "-" "PostmanRuntime/7.37.0" 4 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:17:12,779] INFO 127.0.0.1 - - [09/May/2024:03:17:12 +0000] "DELETE /connectors/JDBC_SOURCE_MYSQL_01 HTTP/1.1" 404 71 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:17:18,867] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:17:18 +0000] "GET /connectors/jdbc_source_mysql_01 HTTP/1.1" 200 529 "-" "PostmanRuntime/7.37.0" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:17:21,577] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:17:21 +0000] "GET /connectors/jdbc_source_mysql_01 HTTP/1.1" 200 529 "-" "PostmanRuntime/7.37.0" 4 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:17:25,081] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:17:25 +0000] "GET /connectors/jdbc_source_mysql_01/status HTTP/1.1" 200 2165 "-" "PostmanRuntime/7.37.0" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:17:30,957] INFO 127.0.0.1 - - [09/May/2024:03:17:30 +0000] "DELETE /connectors/JDBC_SOURCE_ORACLE_01 HTTP/1.1" 404 72 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:17:35,300] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:17:35 +0000] "GET /connectors/jdbc_source_mysql_01/status HTTP/1.1" 200 2165 "-" "PostmanRuntime/7.37.0" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:17:48,298] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:17:48 +0000] "GET /connectors/jdbc_source_mysql_01/status HTTP/1.1" 200 2165 "-" "PostmanRuntime/7.37.0" 1 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:18:04,234] INFO Successfully processed removal of connector 'jdbc_source_mysql_01' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1011)
[2024-05-09 10:18:04,234] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_mysql_01 config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2024-05-09 10:18:04,235] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2024-05-09 10:18:04,235] INFO [jdbc_source_mysql_01|worker] Stopping connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:18:04,235] INFO [jdbc_source_mysql_01|worker] Scheduled shutdown for WorkerConnector{id=jdbc_source_mysql_01} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2024-05-09 10:18:04,235] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:18:04 +0000] "DELETE /connectors/jdbc_source_mysql_01 HTTP/1.1" 204 0 "-" "PostmanRuntime/7.37.0" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:18:04,236] INFO [jdbc_source_mysql_01|worker] Completed shutdown for WorkerConnector{id=jdbc_source_mysql_01} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2024-05-09 10:18:04,236] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:18:04,236] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:18:04,239] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=13, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:18:04,243] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=13, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:18:04,244] INFO [jdbc_source_mysql_01|worker] Stopping connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:18:04,244] WARN [jdbc_source_mysql_01|worker] Ignoring stop request for unowned connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:423)
[2024-05-09 10:18:04,244] WARN [jdbc_source_mysql_01|worker] Ignoring await stop request for non-present connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:444)
[2024-05-09 10:18:04,244] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2024-05-09 10:18:04,244] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2024-05-09 10:18:04,244] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 13 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', leaderUrl='http://127.0.1.1:8083/', offset=18, connectorIds=[jdbc_source_oracle_01], taskIds=[], revokedConnectorIds=[jdbc_source_mysql_01], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:18:04,245] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 18 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:18:04,245] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:18:04,245] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:18:04,245] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:18:04,246] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=14, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:18:04,249] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=14, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:18:04,249] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 14 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', leaderUrl='http://127.0.1.1:8083/', offset=18, connectorIds=[jdbc_source_oracle_01], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:18:04,250] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 18 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:18:04,250] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:18:05,627] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:18:05 +0000] "DELETE /connectors/jdbc_source_mysql_01 HTTP/1.1" 404 71 "-" "PostmanRuntime/7.37.0" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:18:16,318] INFO 127.0.0.1 - - [09/May/2024:03:18:16 +0000] "GET /connectors HTTP/1.1" 200 25 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:18:16,322] INFO 127.0.0.1 - - [09/May/2024:03:18:16 +0000] "GET /connectors/jdbc_source_oracle_01 HTTP/1.1" 200 507 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:18:16,325] INFO 127.0.0.1 - - [09/May/2024:03:18:16 +0000] "GET /connectors/jdbc_source_oracle_01/status HTTP/1.1" 200 2118 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:19:01,378] INFO Successfully processed removal of connector 'jdbc_source_oracle_01' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1011)
[2024-05-09 10:19:01,378] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_oracle_01 config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2024-05-09 10:19:01,379] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2024-05-09 10:19:01,379] INFO [jdbc_source_oracle_01|worker] Stopping connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:19:01,379] INFO [jdbc_source_oracle_01|worker] Scheduled shutdown for WorkerConnector{id=jdbc_source_oracle_01} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2024-05-09 10:19:01,379] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:19:01 +0000] "DELETE /connectors/jdbc_source_oracle_01 HTTP/1.1" 204 0 "-" "PostmanRuntime/7.37.0" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:19:01,380] INFO [jdbc_source_oracle_01|worker] Completed shutdown for WorkerConnector{id=jdbc_source_oracle_01} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2024-05-09 10:19:01,380] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:19:01,380] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:19:01,384] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=15, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:19:01,386] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=15, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:19:01,389] INFO [jdbc_source_oracle_01|worker] Stopping connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:19:01,389] WARN [jdbc_source_oracle_01|worker] Ignoring stop request for unowned connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.Worker:423)
[2024-05-09 10:19:01,389] WARN [jdbc_source_oracle_01|worker] Ignoring await stop request for non-present connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.Worker:444)
[2024-05-09 10:19:01,389] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2024-05-09 10:19:01,390] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2024-05-09 10:19:01,390] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 15 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', leaderUrl='http://127.0.1.1:8083/', offset=20, connectorIds=[], taskIds=[], revokedConnectorIds=[jdbc_source_oracle_01], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:19:01,390] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 20 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:19:01,390] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:19:01,391] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:19:01,391] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:19:01,393] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=16, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:19:01,394] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=16, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:19:01,395] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 16 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', leaderUrl='http://127.0.1.1:8083/', offset=20, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:19:01,395] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 20 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:19:01,395] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:19:04,395] INFO 127.0.0.1 - - [09/May/2024:03:19:04 +0000] "GET /connectors HTTP/1.1" 200 2 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:20:24,440] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/database_name
	connection.user = username
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:20:24,440] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:370)
[2024-05-09 10:20:24,444] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_mysql_02 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2024-05-09 10:20:24,445] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:20:24,445] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:20:24,447] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:20:24 +0000] "POST /connectors HTTP/1.1" 201 409 "-" "PostmanRuntime/7.37.0" 12 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:20:24,447] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=17, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:20:24,450] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=17, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:20:24,450] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 17 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', leaderUrl='http://127.0.1.1:8083/', offset=21, connectorIds=[jdbc_source_mysql_02], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:20:24,451] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 21 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:20:24,451] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector jdbc_source_mysql_02 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 10:20:24,452] INFO [jdbc_source_mysql_02|worker] Creating connector jdbc_source_mysql_02 of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 10:20:24,452] INFO [jdbc_source_mysql_02|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_mysql_02
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 10:20:24,452] INFO [jdbc_source_mysql_02|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_mysql_02
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 10:20:24,453] INFO [jdbc_source_mysql_02|worker] Instantiated connector jdbc_source_mysql_02 with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 10:20:24,454] INFO [jdbc_source_mysql_02|worker] Finished creating connector jdbc_source_mysql_02 (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 10:20:24,454] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:20:24,454] INFO [jdbc_source_mysql_02|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 10:20:24,454] INFO [jdbc_source_mysql_02|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/database_name
	connection.user = username
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:20:24,454] INFO [jdbc_source_mysql_02|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:20:24,455] INFO [jdbc_source_mysql_02|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:20:24,455] INFO [jdbc_source_mysql_02|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:20:24,455] INFO [jdbc_source_mysql_02|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:20:24,455] INFO [jdbc_source_mysql_02|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 10:20:24,456] INFO [jdbc_source_mysql_02|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/database_name
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:20:34,457] INFO [jdbc_source_mysql_02|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/database_name
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:20:35,199] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:20:35 +0000] "GET /connectors HTTP/1.1" 200 24 "-" "PostmanRuntime/7.37.0" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:20:44,458] ERROR [jdbc_source_mysql_02|worker] WorkerConnector{id=jdbc_source_mysql_02} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/database_name
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/database_name
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:20:44,459] ERROR [jdbc_source_mysql_02|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'jdbc_source_mysql_02' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_mysql_02
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector jdbc_source_mysql_02 to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/database_name
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/database_name
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:25:10,504] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:25:10,504] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:26:10,144] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:30:07,337] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/tai_khoan
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [test]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:30:07,338] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:370)
[2024-05-09 10:30:07,346] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_mysql_01 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2024-05-09 10:30:07,347] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:30:07,347] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:30:07,349] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:30:07 +0000] "POST /connectors HTTP/1.1" 201 424 "-" "PostmanRuntime/7.37.0" 19 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:30:07,349] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=18, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:30:07,352] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=18, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:30:07,352] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 18 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', leaderUrl='http://127.0.1.1:8083/', offset=22, connectorIds=[jdbc_source_mysql_01, jdbc_source_mysql_02], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:30:07,352] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 22 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:30:07,353] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 10:30:07,353] INFO [jdbc_source_mysql_01|worker] Creating connector jdbc_source_mysql_01 of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 10:30:07,354] INFO [jdbc_source_mysql_01|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_mysql_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 10:30:07,354] INFO [jdbc_source_mysql_01|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_mysql_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 10:30:07,355] INFO [jdbc_source_mysql_01|worker] Instantiated connector jdbc_source_mysql_01 with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 10:30:07,356] INFO [jdbc_source_mysql_01|worker] Finished creating connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 10:30:07,356] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:30:07,356] INFO [jdbc_source_mysql_01|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 10:30:07,356] INFO [jdbc_source_mysql_01|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/tai_khoan
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [test]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:30:07,356] INFO [jdbc_source_mysql_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:30:07,356] INFO [jdbc_source_mysql_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:30:07,357] INFO [jdbc_source_mysql_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:30:07,357] INFO [jdbc_source_mysql_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:30:07,357] INFO [jdbc_source_mysql_01|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 10:30:07,358] INFO [jdbc_source_mysql_01|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:30:17,359] INFO [jdbc_source_mysql_01|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:30:25,629] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:30:25 +0000] "GET /connectors HTTP/1.1" 200 47 "-" "PostmanRuntime/7.37.0" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:30:27,367] ERROR [jdbc_source_mysql_01|worker] WorkerConnector{id=jdbc_source_mysql_01} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:30:27,370] ERROR [jdbc_source_mysql_01|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'jdbc_source_mysql_01' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_mysql_01
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector jdbc_source_mysql_01 to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:30:36,156] INFO Successfully processed removal of connector 'jdbc_source_mysql_01' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1011)
[2024-05-09 10:30:36,156] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_mysql_01 config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2024-05-09 10:30:36,157] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2024-05-09 10:30:36,157] INFO [jdbc_source_mysql_01|worker] Stopping connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:30:36,157] INFO [jdbc_source_mysql_01|worker] Scheduled shutdown for WorkerConnector{id=jdbc_source_mysql_01} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2024-05-09 10:30:36,157] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:30:36 +0000] "DELETE /connectors/jdbc_source_mysql_01 HTTP/1.1" 204 0 "-" "PostmanRuntime/7.37.0" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:30:36,157] INFO [jdbc_source_mysql_01|worker] Completed shutdown for WorkerConnector{id=jdbc_source_mysql_01} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2024-05-09 10:30:36,158] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:30:36,158] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:30:36,160] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=19, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:30:36,164] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=19, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:30:36,165] INFO [jdbc_source_mysql_01|worker] Stopping connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:30:36,165] WARN [jdbc_source_mysql_01|worker] Ignoring stop request for unowned connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:423)
[2024-05-09 10:30:36,165] WARN [jdbc_source_mysql_01|worker] Ignoring await stop request for non-present connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:444)
[2024-05-09 10:30:36,165] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2024-05-09 10:30:36,167] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2024-05-09 10:30:36,167] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 19 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', leaderUrl='http://127.0.1.1:8083/', offset=24, connectorIds=[jdbc_source_mysql_02], taskIds=[], revokedConnectorIds=[jdbc_source_mysql_01], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:30:36,168] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 24 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:30:36,168] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:30:36,168] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:30:36,168] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:30:36,171] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=20, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:30:36,174] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=20, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:30:36,174] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 20 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', leaderUrl='http://127.0.1.1:8083/', offset=24, connectorIds=[jdbc_source_mysql_02], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:30:36,175] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 24 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:30:36,175] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:30:44,974] INFO Successfully processed removal of connector 'jdbc_source_mysql_02' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1011)
[2024-05-09 10:30:44,974] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_mysql_02 config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2024-05-09 10:30:44,974] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector jdbc_source_mysql_02 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2024-05-09 10:30:44,974] INFO [jdbc_source_mysql_02|worker] Stopping connector jdbc_source_mysql_02 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:30:44,975] INFO [jdbc_source_mysql_02|worker] Scheduled shutdown for WorkerConnector{id=jdbc_source_mysql_02} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2024-05-09 10:30:44,975] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:30:44 +0000] "DELETE /connectors/jdbc_source_mysql_02 HTTP/1.1" 204 0 "-" "PostmanRuntime/7.37.0" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:30:44,975] INFO [jdbc_source_mysql_02|worker] Completed shutdown for WorkerConnector{id=jdbc_source_mysql_02} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2024-05-09 10:30:44,976] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:30:44,976] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:30:44,978] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=21, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:30:44,981] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=21, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:30:44,981] INFO [jdbc_source_mysql_02|worker] Stopping connector jdbc_source_mysql_02 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:30:44,981] WARN [jdbc_source_mysql_02|worker] Ignoring stop request for unowned connector jdbc_source_mysql_02 (org.apache.kafka.connect.runtime.Worker:423)
[2024-05-09 10:30:44,981] WARN [jdbc_source_mysql_02|worker] Ignoring await stop request for non-present connector jdbc_source_mysql_02 (org.apache.kafka.connect.runtime.Worker:444)
[2024-05-09 10:30:44,982] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2024-05-09 10:30:44,982] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2024-05-09 10:30:44,982] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 21 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', leaderUrl='http://127.0.1.1:8083/', offset=26, connectorIds=[], taskIds=[], revokedConnectorIds=[jdbc_source_mysql_02], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:30:44,982] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 26 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:30:44,982] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:30:44,983] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:30:44,983] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:30:44,984] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=22, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:30:44,987] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=22, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:30:44,987] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 22 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', leaderUrl='http://127.0.1.1:8083/', offset=26, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:30:44,988] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 26 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:30:44,988] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:30:49,318] INFO 127.0.0.1 - - [09/May/2024:03:30:49 +0000] "GET /connectors HTTP/1.1" 200 2 "-" "Apache-HttpClient/5.0.3 (Java/17.0.10)" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:30:54,897] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://192.168.1.2:3306/tai_khoan
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [test]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:30:54,897] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:370)
[2024-05-09 10:30:54,903] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_mysql_01 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2024-05-09 10:30:54,904] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:30:54,904] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:30:54,906] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:30:54 +0000] "POST /connectors HTTP/1.1" 201 426 "-" "PostmanRuntime/7.37.0" 14 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:30:54,906] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=23, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:30:54,908] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=23, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:30:54,909] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 23 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', leaderUrl='http://127.0.1.1:8083/', offset=27, connectorIds=[jdbc_source_mysql_01], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:30:54,909] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 27 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:30:54,909] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 10:30:54,909] INFO [jdbc_source_mysql_01|worker] Creating connector jdbc_source_mysql_01 of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 10:30:54,909] INFO [jdbc_source_mysql_01|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_mysql_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 10:30:54,910] INFO [jdbc_source_mysql_01|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_mysql_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 10:30:54,910] INFO [jdbc_source_mysql_01|worker] Instantiated connector jdbc_source_mysql_01 with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 10:30:54,910] INFO [jdbc_source_mysql_01|worker] Finished creating connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 10:30:54,910] INFO [jdbc_source_mysql_01|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 10:30:54,910] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:30:54,911] INFO [jdbc_source_mysql_01|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://192.168.1.2:3306/tai_khoan
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [test]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:30:54,911] INFO [jdbc_source_mysql_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:30:54,911] INFO [jdbc_source_mysql_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:30:54,911] INFO [jdbc_source_mysql_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:30:54,911] INFO [jdbc_source_mysql_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:30:54,911] INFO [jdbc_source_mysql_01|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 10:30:54,912] INFO [jdbc_source_mysql_01|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:31:04,913] INFO [jdbc_source_mysql_01|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:31:05,711] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:31:05 +0000] "GET /connectors HTTP/1.1" 200 24 "-" "PostmanRuntime/7.37.0" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:31:14,914] ERROR [jdbc_source_mysql_01|worker] WorkerConnector{id=jdbc_source_mysql_01} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:31:14,915] ERROR [jdbc_source_mysql_01|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'jdbc_source_mysql_01' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_mysql_01
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector jdbc_source_mysql_01 to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:36:10,354] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:41:10,524] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:42:22,515] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/tai_khoan
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [test]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:42:22,515] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:370)
[2024-05-09 10:42:22,523] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_mysql_02 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2024-05-09 10:42:22,524] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:42:22,524] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:42:22,525] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:42:22 +0000] "POST /connectors HTTP/1.1" 201 418 "-" "PostmanRuntime/7.37.0" 20 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:42:22,526] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=24, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:42:22,531] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=24, memberId='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:42:22,531] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 24 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256', leaderUrl='http://127.0.1.1:8083/', offset=28, connectorIds=[jdbc_source_mysql_02, jdbc_source_mysql_01], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:42:22,532] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 28 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:42:22,532] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector jdbc_source_mysql_02 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 10:42:22,532] INFO [jdbc_source_mysql_02|worker] Creating connector jdbc_source_mysql_02 of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 10:42:22,532] INFO [jdbc_source_mysql_02|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_mysql_02
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 10:42:22,533] INFO [jdbc_source_mysql_02|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_mysql_02
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 10:42:22,533] INFO [jdbc_source_mysql_02|worker] Instantiated connector jdbc_source_mysql_02 with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 10:42:22,534] INFO [jdbc_source_mysql_02|worker] Finished creating connector jdbc_source_mysql_02 (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 10:42:22,534] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:42:22,534] INFO [jdbc_source_mysql_02|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 10:42:22,534] INFO [jdbc_source_mysql_02|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/tai_khoan
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [test]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:42:22,534] INFO [jdbc_source_mysql_02|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:42:22,534] INFO [jdbc_source_mysql_02|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:42:22,535] INFO [jdbc_source_mysql_02|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:42:22,535] INFO [jdbc_source_mysql_02|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:42:22,535] INFO [jdbc_source_mysql_02|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 10:42:22,536] INFO [jdbc_source_mysql_02|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:42:32,330] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2024-05-09 10:42:32,332] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:348)
[2024-05-09 10:42:32,341] INFO Stopped http_8083@22c0344e{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2024-05-09 10:42:32,342] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2024-05-09 10:42:32,348] INFO Stopped o.e.j.s.ServletContextHandler@19542115{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler:1159)
[2024-05-09 10:42:32,349] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:377)
[2024-05-09 10:42:32,349] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:831)
[2024-05-09 10:42:32,349] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:794)
[2024-05-09 10:42:32,349] INFO [jdbc_source_mysql_01|worker] Stopping connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:42:32,349] INFO [jdbc_source_mysql_01|worker] Scheduled shutdown for WorkerConnector{id=jdbc_source_mysql_01} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2024-05-09 10:42:32,349] INFO [jdbc_source_mysql_02|worker] Stopping connector jdbc_source_mysql_02 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:42:32,349] INFO [jdbc_source_mysql_02|worker] Scheduled shutdown for WorkerConnector{id=jdbc_source_mysql_02} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2024-05-09 10:42:32,351] INFO [jdbc_source_mysql_01|worker] Completed shutdown for WorkerConnector{id=jdbc_source_mysql_01} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2024-05-09 10:42:32,538] INFO [jdbc_source_mysql_02|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:42:37,349] ERROR [jdbc_source_mysql_02|worker] Connector 'jdbc_source_mysql_02' failed to properly shut down, has become unresponsive, and may be consuming external resources. Correct the configuration for this connector or remove the connector. After fixing the connector, it may be necessary to restart this worker to release any consumed resources. (org.apache.kafka.connect.runtime.Worker:449)
[2024-05-09 10:42:37,350] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Member connect-127.0.1.1:8083-07b22120-19f2-4b6e-b726-5d1ed0584256 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: null) due to the consumer is being closed (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1163)
[2024-05-09 10:42:37,351] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1055)
[2024-05-09 10:42:37,351] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1140)
[2024-05-09 10:42:37,351] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 10:42:37,351] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:42:37,352] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 10:42:37,355] INFO App info kafka.connect for connect-127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 10:42:37,355] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:292)
[2024-05-09 10:42:37,356] INFO [Producer clientId=connect-cluster-statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2024-05-09 10:42:37,361] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 10:42:37,361] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:42:37,361] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:42:37,361] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 10:42:37,362] INFO App info kafka.producer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 10:42:37,365] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2024-05-09 10:42:37,365] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2024-05-09 10:42:37,858] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 10:42:37,858] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:42:37,859] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:42:37,859] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 10:42:37,861] INFO App info kafka.consumer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 10:42:37,861] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2024-05-09 10:42:37,861] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:407)
[2024-05-09 10:42:37,861] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:292)
[2024-05-09 10:42:37,861] INFO [Producer clientId=connect-cluster-configs] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2024-05-09 10:42:37,864] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 10:42:37,864] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:42:37,864] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:42:37,864] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 10:42:37,864] INFO App info kafka.producer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 10:42:37,864] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2024-05-09 10:42:37,864] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2024-05-09 10:42:38,052] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 10:42:38,052] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:42:38,052] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:42:38,052] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 10:42:38,053] INFO App info kafka.consumer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 10:42:38,053] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2024-05-09 10:42:38,053] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:413)
[2024-05-09 10:42:38,054] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:248)
[2024-05-09 10:42:38,055] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:269)
[2024-05-09 10:42:38,055] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:292)
[2024-05-09 10:42:38,055] INFO [Producer clientId=connect-cluster-offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2024-05-09 10:42:38,057] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 10:42:38,057] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:42:38,057] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:42:38,057] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 10:42:38,058] INFO App info kafka.producer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 10:42:38,058] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2024-05-09 10:42:38,058] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2024-05-09 10:42:38,498] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 10:42:38,499] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:42:38,499] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:42:38,499] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 10:42:38,500] INFO App info kafka.consumer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 10:42:38,500] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2024-05-09 10:42:38,500] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:277)
[2024-05-09 10:42:38,501] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 10:42:38,501] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:42:38,501] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 10:42:38,501] INFO App info kafka.connect for 127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 10:42:38,501] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:269)
[2024-05-09 10:42:39,511] ERROR [jdbc_source_mysql_02|worker] WorkerConnector{id=jdbc_source_mysql_02} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:42:39,511] ERROR [jdbc_source_mysql_02|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'jdbc_source_mysql_02' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_mysql_02
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector jdbc_source_mysql_02 to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:42:39,511] INFO [jdbc_source_mysql_02|worker] Completed shutdown for WorkerConnector{id=jdbc_source_mysql_02} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2024-05-09 10:42:39,514] INFO App info kafka.admin.client for connect-cluster-shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 10:42:39,515] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 10:42:39,515] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:42:39,515] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 10:42:39,515] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:386)
[2024-05-09 10:42:39,516] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:838)
[2024-05-09 10:42:39,516] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2024-05-09 10:42:42,836] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2024-05-09 10:42:42,841] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/macmkay/kafka/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 17.0.10, 17.0.10+7-Ubuntu-122.04.1
	jvm.classpath = /home/macmkay/kafka/bin/../libs/activation-1.1.1.jar:/home/macmkay/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/macmkay/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/macmkay/kafka/bin/../libs/audience-annotations-0.12.0.jar:/home/macmkay/kafka/bin/../libs/caffeine-2.9.3.jar:/home/macmkay/kafka/bin/../libs/checker-qual-3.19.0.jar:/home/macmkay/kafka/bin/../libs/commons-beanutils-1.9.4.jar:/home/macmkay/kafka/bin/../libs/commons-cli-1.4.jar:/home/macmkay/kafka/bin/../libs/commons-collections-3.2.2.jar:/home/macmkay/kafka/bin/../libs/commons-digester-2.1.jar:/home/macmkay/kafka/bin/../libs/commons-io-2.11.0.jar:/home/macmkay/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/macmkay/kafka/bin/../libs/commons-logging-1.2.jar:/home/macmkay/kafka/bin/../libs/commons-validator-1.7.jar:/home/macmkay/kafka/bin/../libs/connect-api-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-basic-auth-extension-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-json-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-mirror-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-mirror-client-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-runtime-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-transforms-3.7.0.jar:/home/macmkay/kafka/bin/../libs/error_prone_annotations-2.10.0.jar:/home/macmkay/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/macmkay/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/macmkay/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/macmkay/kafka/bin/../libs/jackson-annotations-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-core-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-databind-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-dataformat-csv-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-datatype-jdk8-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-jaxrs-base-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-jaxrs-json-provider-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-module-jaxb-annotations-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-module-scala_2.13-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jakarta.activation-api-1.2.2.jar:/home/macmkay/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/macmkay/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/macmkay/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/macmkay/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/macmkay/kafka/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/home/macmkay/kafka/bin/../libs/javassist-3.29.2-GA.jar:/home/macmkay/kafka/bin/../libs/javax.activation-api-1.2.0.jar:/home/macmkay/kafka/bin/../libs/javax.annotation-api-1.3.2.jar:/home/macmkay/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/macmkay/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/macmkay/kafka/bin/../libs/jaxb-api-2.3.1.jar:/home/macmkay/kafka/bin/../libs/jersey-client-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-common-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-container-servlet-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-hk2-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-server-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jetty-client-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-continuation-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-http-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-io-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-security-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-server-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-servlet-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-servlets-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-util-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-util-ajax-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jline-3.22.0.jar:/home/macmkay/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/macmkay/kafka/bin/../libs/jose4j-0.9.4.jar:/home/macmkay/kafka/bin/../libs/jsr305-3.0.2.jar:/home/macmkay/kafka/bin/../libs/kafka-clients-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-group-coordinator-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-log4j-appender-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-metadata-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-raft-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-server-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-server-common-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-shell-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-storage-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-storage-api-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-streams-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-streams-examples-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-streams-scala_2.13-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-streams-test-utils-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-tools-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-tools-api-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka_2.13-3.7.0.jar:/home/macmkay/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/macmkay/kafka/bin/../libs/maven-artifact-3.8.8.jar:/home/macmkay/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/macmkay/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/macmkay/kafka/bin/../libs/netty-buffer-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-codec-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-common-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-handler-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-resolver-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-transport-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-transport-classes-epoll-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-transport-native-epoll-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-transport-native-unix-common-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/home/macmkay/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/macmkay/kafka/bin/../libs/paranamer-2.8.jar:/home/macmkay/kafka/bin/../libs/pcollections-4.0.1.jar:/home/macmkay/kafka/bin/../libs/plexus-utils-3.3.1.jar:/home/macmkay/kafka/bin/../libs/protobuf-java-3.23.4.jar:/home/macmkay/kafka/bin/../libs/reflections-0.10.2.jar:/home/macmkay/kafka/bin/../libs/reload4j-1.2.25.jar:/home/macmkay/kafka/bin/../libs/rocksdbjni-7.9.2.jar:/home/macmkay/kafka/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/home/macmkay/kafka/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/home/macmkay/kafka/bin/../libs/scala-library-2.13.12.jar:/home/macmkay/kafka/bin/../libs/scala-logging_2.13-3.9.4.jar:/home/macmkay/kafka/bin/../libs/scala-reflect-2.13.12.jar:/home/macmkay/kafka/bin/../libs/slf4j-api-1.7.36.jar:/home/macmkay/kafka/bin/../libs/slf4j-reload4j-1.7.36.jar:/home/macmkay/kafka/bin/../libs/snappy-java-1.1.10.5.jar:/home/macmkay/kafka/bin/../libs/swagger-annotations-2.2.8.jar:/home/macmkay/kafka/bin/../libs/trogdor-3.7.0.jar:/home/macmkay/kafka/bin/../libs/zookeeper-3.8.3.jar:/home/macmkay/kafka/bin/../libs/zookeeper-jute-3.8.3.jar:/home/macmkay/kafka/bin/../libs/zstd-jni-1.5.5-6.jar
	os.spec = Linux, amd64, 5.15.146.1-microsoft-standard-WSL2
	os.vcpus = 12
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2024-05-09 10:42:42,842] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2024-05-09 10:42:42,866] INFO Loading plugin from: /home/macmkay/kafka/./libs/connect-file-3.7.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,071] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/./libs/connect-file-3.7.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,073] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/jtds-1.3.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,080] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/jtds-1.3.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,085] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/slf4j-api-1.7.36.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,092] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/slf4j-api-1.7.36.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,092] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/checker-qual-3.5.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,100] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/checker-qual-3.5.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,100] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/kafka-connect-jdbc-10.7.6.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,107] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/kafka-connect-jdbc-10.7.6.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,108] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ons-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,115] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ons-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,115] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xmlparserv2-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,125] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xmlparserv2-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,126] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/oraclepki-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,134] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/oraclepki-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,135] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/postgresql-42.4.4.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,140] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/postgresql-42.4.4.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,144] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/simplefan-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,149] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/simplefan-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,149] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_cert-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,154] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_cert-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,154] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/sqlite-jdbc-3.41.2.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,159] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/sqlite-jdbc-3.41.2.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,163] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xdb-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,166] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xdb-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,167] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ucp-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,172] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ucp-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,173] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/mssql-jdbc-8.4.1.jre8.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,177] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/mssql-jdbc-8.4.1.jre8.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,296] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_core-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,310] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_core-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,310] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/common-utils-6.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,315] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/common-utils-6.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,315] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ojdbc8-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,322] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ojdbc8-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,351] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/orai18n-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,356] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/orai18n-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,356] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,362] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@1dbd16a6 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,362] INFO Scanning plugins with ServiceLoaderScanner took 497 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2024-05-09 10:42:43,363] INFO Loading plugin from: /home/macmkay/kafka/./libs/connect-file-3.7.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,414] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/./libs/connect-file-3.7.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,414] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/jtds-1.3.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,451] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/jtds-1.3.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,452] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/slf4j-api-1.7.36.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,459] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/slf4j-api-1.7.36.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,459] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/checker-qual-3.5.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,484] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/checker-qual-3.5.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,485] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/kafka-connect-jdbc-10.7.6.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,507] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/kafka-connect-jdbc-10.7.6.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,507] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ons-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,520] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ons-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,520] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xmlparserv2-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,670] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xmlparserv2-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,671] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/oraclepki-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,696] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/oraclepki-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,696] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/postgresql-42.4.4.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,806] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/postgresql-42.4.4.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,807] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/simplefan-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,816] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/simplefan-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,816] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_cert-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,837] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_cert-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,838] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/sqlite-jdbc-3.41.2.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,867] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/sqlite-jdbc-3.41.2.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,867] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xdb-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,890] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xdb-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,891] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ucp-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:43,998] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ucp-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:43,999] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/mssql-jdbc-8.4.1.jre8.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:44,076] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/mssql-jdbc-8.4.1.jre8.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:44,082] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_core-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:44,100] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_core-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:44,101] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/common-utils-6.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:44,104] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/common-utils-6.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:44,104] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ojdbc8-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:44,314] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ojdbc8-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:44,314] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/orai18n-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:44,321] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/orai18n-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:44,322] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 10:42:45,307] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@1dbd16a6 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 10:42:45,307] INFO Scanning plugins with ReflectionScanner took 1944 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2024-05-09 10:42:45,314] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/kafka-connect-jdbc-10.7.6.jar	io.confluent.connect.jdbc.JdbcSinkConnector	sink	10.7.6
file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/kafka-connect-jdbc-10.7.6.jar	io.confluent.connect.jdbc.JdbcSourceConnector	source	10.7.6
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:122)
[2024-05-09 10:42:45,316] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,316] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,317] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,317] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,317] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,317] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,317] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,317] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,317] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,318] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,318] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,318] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,318] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,318] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,318] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,318] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,318] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,319] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,319] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,319] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,319] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,319] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,319] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,319] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,319] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,319] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,320] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,320] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,320] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,320] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,320] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,320] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,320] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,320] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,320] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,321] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,321] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,321] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,321] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,321] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,321] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,321] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,322] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,322] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,322] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,322] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,322] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,322] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,322] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,322] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,322] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,323] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,323] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 10:42:45,326] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,326] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,327] INFO Added alias 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,327] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,327] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,327] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,327] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,327] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,327] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,327] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,327] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,328] INFO Added alias 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,328] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,328] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,328] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,328] INFO Added alias 'FileStreamSinkConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,328] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,328] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,328] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,328] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,329] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,329] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,329] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,329] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,329] INFO Added alias 'FileStreamSourceConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,330] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,330] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,330] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,330] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,330] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,330] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,330] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,330] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,330] INFO Added alias 'JdbcSinkConnector' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,330] INFO Added alias 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,330] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,331] INFO Added alias 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,331] INFO Added alias 'JdbcSourceConnector' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,331] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,331] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,331] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,331] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,331] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,332] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,332] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,332] INFO Added alias 'ByteArrayConverter' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,332] INFO Added alias 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,332] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,332] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,332] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,332] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,332] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,332] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,332] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,333] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,333] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 10:42:45,367] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [./libs/connect-file-3.7.0.jar, ../confluentinc-kafka-connect-jdbc/lib]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = SASL_PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:370)
[2024-05-09 10:42:45,369] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:283)
[2024-05-09 10:42:45,372] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-05-09 10:42:45,423] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin:61)
[2024-05-09 10:42:45,444] INFO These configurations '[producer.sasl.jaas.config, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, status.storage.topic, group.id, plugin.path, consumer.sasl.mechanism, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-05-09 10:42:45,444] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 10:42:45,444] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 10:42:45,445] INFO Kafka startTimeMs: 1715226165444 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 10:42:45,680] INFO Kafka cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.connect.runtime.WorkerConfig:300)
[2024-05-09 10:42:45,681] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 10:42:45,685] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 10:42:45,686] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 10:42:45,686] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 10:42:45,688] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:370)
[2024-05-09 10:42:45,693] INFO Logging initialized @3454ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2024-05-09 10:42:45,719] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:111)
[2024-05-09 10:42:45,719] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:182)
[2024-05-09 10:42:45,737] INFO jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 17.0.10+7-Ubuntu-122.04.1 (org.eclipse.jetty.server.Server:375)
[2024-05-09 10:42:45,755] INFO Started http_8083@22c0344e{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2024-05-09 10:42:45,756] INFO Started @3516ms (org.eclipse.jetty.server.Server:415)
[2024-05-09 10:42:45,772] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:406)
[2024-05-09 10:42:45,772] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:202)
[2024-05-09 10:42:45,772] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:406)
[2024-05-09 10:42:45,772] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:205)
[2024-05-09 10:42:45,772] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:406)
[2024-05-09 10:42:45,773] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2024-05-09 10:42:45,779] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:370)
[2024-05-09 10:42:45,795] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 10:42:45,796] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 10:42:45,796] INFO Kafka startTimeMs: 1715226165795 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 10:42:45,800] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:370)
[2024-05-09 10:42:45,800] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:370)
[2024-05-09 10:42:45,824] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:406)
[2024-05-09 10:42:45,867] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin:61)
[2024-05-09 10:42:45,882] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 10:42:45,882] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 10:42:45,883] INFO Kafka startTimeMs: 1715226165882 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 10:42:45,885] INFO Kafka Connect worker initialization took 3048ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2024-05-09 10:42:45,886] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2024-05-09 10:42:45,892] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:209)
[2024-05-09 10:42:45,892] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:369)
[2024-05-09 10:42:45,894] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:231)
[2024-05-09 10:42:45,894] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:240)
[2024-05-09 10:42:45,894] INFO Starting KafkaBasedLog with topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2024-05-09 10:42:45,895] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-05-09 10:42:45,899] INFO These configurations '[producer.sasl.jaas.config, group.id, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-05-09 10:42:45,906] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 10:42:45,907] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 10:42:45,907] INFO Kafka startTimeMs: 1715226165899 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 10:42:45,941] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:227)
[2024-05-09 10:42:45,970] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2024-05-09 10:42:45,970] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2024-05-09 10:42:45,971] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2024-05-09 10:42:45,991] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-05-09 10:42:46,007] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 10:42:46,025] INFO These configurations '[producer.sasl.jaas.config, group.id, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-05-09 10:42:46,026] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 10:42:46,026] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 10:42:46,026] INFO Kafka startTimeMs: 1715226166026 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 10:42:46,031] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-05-09 10:42:46,035] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 10:42:46,039] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 10:42:46,061] INFO These configurations '[producer.sasl.jaas.config, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-05-09 10:42:46,061] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 10:42:46,061] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 10:42:46,061] INFO Kafka startTimeMs: 1715226166061 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 10:42:46,069] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 10:42:46,075] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-17, connect-offsets-20, connect-offsets-11, connect-offsets-23, connect-offsets-14, connect-offsets-5, connect-offsets-0, connect-offsets-8, connect-offsets-7, connect-offsets-4, connect-offsets-1, connect-offsets-10, connect-offsets-13, connect-offsets-24, connect-offsets-21, connect-offsets-16, connect-offsets-3, connect-offsets-9, connect-offsets-15, connect-offsets-18, connect-offsets-19, connect-offsets-22, connect-offsets-6, connect-offsets-2, connect-offsets-12 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2024-05-09 10:42:46,077] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,078] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,078] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,078] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,078] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,078] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,078] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,079] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,079] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,079] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,079] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,079] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,079] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,079] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,079] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,079] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,079] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,079] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,080] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,080] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,080] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,080] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,080] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,080] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,080] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,112] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,112] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,113] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,113] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,113] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,113] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,113] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,113] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,113] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,113] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,114] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,114] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,114] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,114] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,114] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,114] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,114] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,114] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,115] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,115] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,115] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,115] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,115] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,115] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,115] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,116] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2024-05-09 10:42:46,116] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2024-05-09 10:42:46,116] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:257)
[2024-05-09 10:42:46,117] INFO Worker started (org.apache.kafka.connect.runtime.Worker:241)
[2024-05-09 10:42:46,117] INFO Starting KafkaBasedLog with topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2024-05-09 10:42:46,124] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-05-09 10:42:46,125] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 10:42:46,131] INFO These configurations '[producer.sasl.jaas.config, group.id, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-05-09 10:42:46,131] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 10:42:46,131] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 10:42:46,131] INFO Kafka startTimeMs: 1715226166131 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 10:42:46,132] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-05-09 10:42:46,133] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 10:42:46,137] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 10:42:46,138] INFO These configurations '[producer.sasl.jaas.config, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-05-09 10:42:46,138] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 10:42:46,139] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 10:42:46,139] INFO Kafka startTimeMs: 1715226166138 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 10:42:46,143] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 10:42:46,144] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-1, connect-status-3, connect-status-2, connect-status-0, connect-status-4 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2024-05-09 10:42:46,144] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,144] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,144] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,144] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,144] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,154] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,154] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,154] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,154] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,154] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,196] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2024-05-09 10:42:46,196] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2024-05-09 10:42:46,199] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:378)
[2024-05-09 10:42:46,199] INFO Starting KafkaBasedLog with topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2024-05-09 10:42:46,208] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-05-09 10:42:46,209] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 10:42:46,214] INFO These configurations '[producer.sasl.jaas.config, group.id, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-05-09 10:42:46,214] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 10:42:46,214] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 10:42:46,214] INFO Kafka startTimeMs: 1715226166214 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 10:42:46,215] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-05-09 10:42:46,215] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 10:42:46,219] INFO These configurations '[producer.sasl.jaas.config, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-05-09 10:42:46,219] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 10:42:46,219] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 10:42:46,220] INFO [Producer clientId=connect-cluster-configs] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 10:42:46,220] INFO Kafka startTimeMs: 1715226166219 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 10:42:46,224] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 10:42:46,224] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2024-05-09 10:42:46,224] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 10:42:46,233] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 10:42:46,240] INFO Successfully processed removal of connector 'MYSQL_SOURCE_CONNECTOR' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1011)
[2024-05-09 10:42:46,241] INFO Successfully processed removal of connector 'jdbc_source_mysql_01' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1011)
[2024-05-09 10:42:46,241] INFO Successfully processed removal of connector 'jdbc_source_oracle_01' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1011)
[2024-05-09 10:42:46,241] INFO Successfully processed removal of connector 'jdbc_source_mysql_01' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1011)
[2024-05-09 10:42:46,241] INFO Successfully processed removal of connector 'jdbc_source_mysql_02' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1011)
[2024-05-09 10:42:46,242] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2024-05-09 10:42:46,242] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2024-05-09 10:42:46,242] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:402)
[2024-05-09 10:42:46,242] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:376)
[2024-05-09 10:42:46,251] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 10:42:46,252] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2024-05-09 10:42:46,255] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:42:46,255] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:42:46,266] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:42:46,321] INFO Started o.e.j.s.ServletContextHandler@19542115{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2024-05-09 10:42:46,321] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:302)
[2024-05-09 10:42:46,321] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2024-05-09 10:42:49,272] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=26, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:42:49,288] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=26, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:42:49,289] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 26 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', leaderUrl='http://127.0.1.1:8083/', offset=28, connectorIds=[jdbc_source_mysql_01, jdbc_source_mysql_02], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:42:49,290] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1753)
[2024-05-09 10:42:49,290] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Current config state offset -1 is behind group assignment 28, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1826)
[2024-05-09 10:42:49,292] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 28 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1853)
[2024-05-09 10:42:49,292] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 28 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:42:49,294] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 10:42:49,294] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector jdbc_source_mysql_02 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 10:42:49,297] INFO [jdbc_source_mysql_01|worker] Creating connector jdbc_source_mysql_01 of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 10:42:49,297] INFO [jdbc_source_mysql_02|worker] Creating connector jdbc_source_mysql_02 of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 10:42:49,299] INFO [jdbc_source_mysql_01|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_mysql_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 10:42:49,299] INFO [jdbc_source_mysql_02|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_mysql_02
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 10:42:49,300] INFO [jdbc_source_mysql_01|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_mysql_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 10:42:49,300] INFO [jdbc_source_mysql_02|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_mysql_02
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 10:42:49,306] INFO [jdbc_source_mysql_02|worker] Instantiated connector jdbc_source_mysql_02 with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 10:42:49,306] INFO [jdbc_source_mysql_01|worker] Instantiated connector jdbc_source_mysql_01 with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 10:42:49,306] INFO [jdbc_source_mysql_02|worker] Finished creating connector jdbc_source_mysql_02 (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 10:42:49,307] INFO [jdbc_source_mysql_01|worker] Finished creating connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 10:42:49,307] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:42:49,308] INFO [jdbc_source_mysql_02|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 10:42:49,308] INFO [jdbc_source_mysql_01|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 10:42:49,322] INFO [jdbc_source_mysql_02|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/tai_khoan
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [test]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:42:49,322] INFO [jdbc_source_mysql_01|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://192.168.1.2:3306/tai_khoan
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [test]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:42:49,323] INFO [jdbc_source_mysql_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:42:49,323] INFO [jdbc_source_mysql_02|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:42:49,323] INFO [jdbc_source_mysql_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:42:49,323] INFO [jdbc_source_mysql_02|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:42:49,326] INFO [jdbc_source_mysql_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:42:49,326] INFO [jdbc_source_mysql_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:42:49,326] INFO [jdbc_source_mysql_02|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:42:49,326] INFO [jdbc_source_mysql_02|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:42:49,327] INFO [jdbc_source_mysql_01|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 10:42:49,327] INFO [jdbc_source_mysql_02|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 10:42:49,328] INFO [jdbc_source_mysql_02|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:42:49,328] INFO [jdbc_source_mysql_01|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:42:59,331] INFO [jdbc_source_mysql_02|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:42:59,331] INFO [jdbc_source_mysql_01|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:43:09,334] ERROR [jdbc_source_mysql_01|worker] WorkerConnector{id=jdbc_source_mysql_01} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:43:09,334] ERROR [jdbc_source_mysql_02|worker] WorkerConnector{id=jdbc_source_mysql_02} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:43:09,356] ERROR [jdbc_source_mysql_01|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'jdbc_source_mysql_01' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_mysql_01
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector jdbc_source_mysql_01 to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:43:09,356] ERROR [jdbc_source_mysql_02|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'jdbc_source_mysql_02' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_mysql_02
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector jdbc_source_mysql_02 to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:46:30,594] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:46:30 +0000] "GET /connectors HTTP/1.1" 200 47 "-" "PostmanRuntime/7.37.0" 68 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:46:37,451] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:46:37 +0000] "DELETE /connectors/jdbc_source_mysql_02%22 HTTP/1.1" 404 73 "-" "PostmanRuntime/7.37.0" 29 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:46:40,464] INFO Successfully processed removal of connector 'jdbc_source_mysql_02' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1011)
[2024-05-09 10:46:40,464] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_mysql_02 config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2024-05-09 10:46:40,465] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector jdbc_source_mysql_02 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2024-05-09 10:46:40,465] INFO [jdbc_source_mysql_02|worker] Stopping connector jdbc_source_mysql_02 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:46:40,465] INFO [jdbc_source_mysql_02|worker] Scheduled shutdown for WorkerConnector{id=jdbc_source_mysql_02} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2024-05-09 10:46:40,466] INFO [jdbc_source_mysql_02|worker] Completed shutdown for WorkerConnector{id=jdbc_source_mysql_02} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2024-05-09 10:46:40,466] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:46:40 +0000] "DELETE /connectors/jdbc_source_mysql_02 HTTP/1.1" 204 0 "-" "PostmanRuntime/7.37.0" 13 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:46:40,468] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:46:40,469] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:46:40,471] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=27, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:46:40,479] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=27, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:46:40,480] INFO [jdbc_source_mysql_02|worker] Stopping connector jdbc_source_mysql_02 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:46:40,481] WARN [jdbc_source_mysql_02|worker] Ignoring stop request for unowned connector jdbc_source_mysql_02 (org.apache.kafka.connect.runtime.Worker:423)
[2024-05-09 10:46:40,481] WARN [jdbc_source_mysql_02|worker] Ignoring await stop request for non-present connector jdbc_source_mysql_02 (org.apache.kafka.connect.runtime.Worker:444)
[2024-05-09 10:46:40,481] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2024-05-09 10:46:40,482] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2024-05-09 10:46:40,482] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 27 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', leaderUrl='http://127.0.1.1:8083/', offset=30, connectorIds=[jdbc_source_mysql_01], taskIds=[], revokedConnectorIds=[jdbc_source_mysql_02], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:46:40,483] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 30 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:46:40,483] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:46:40,483] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:46:40,483] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:46:40,486] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=28, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:46:40,490] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=28, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:46:40,490] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 28 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', leaderUrl='http://127.0.1.1:8083/', offset=30, connectorIds=[jdbc_source_mysql_01], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:46:40,491] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 30 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:46:40,491] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:46:42,157] INFO Successfully processed removal of connector 'jdbc_source_mysql_01' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1011)
[2024-05-09 10:46:42,157] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_mysql_01 config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2024-05-09 10:46:42,157] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2024-05-09 10:46:42,158] INFO [jdbc_source_mysql_01|worker] Stopping connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:46:42,158] INFO [jdbc_source_mysql_01|worker] Scheduled shutdown for WorkerConnector{id=jdbc_source_mysql_01} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2024-05-09 10:46:42,158] INFO [jdbc_source_mysql_01|worker] Completed shutdown for WorkerConnector{id=jdbc_source_mysql_01} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2024-05-09 10:46:42,158] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:46:42 +0000] "DELETE /connectors/jdbc_source_mysql_01 HTTP/1.1" 204 0 "-" "PostmanRuntime/7.37.0" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:46:42,159] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:46:42,159] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:46:42,161] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=29, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:46:42,163] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=29, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:46:42,164] INFO [jdbc_source_mysql_01|worker] Stopping connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:46:42,165] WARN [jdbc_source_mysql_01|worker] Ignoring stop request for unowned connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:423)
[2024-05-09 10:46:42,165] WARN [jdbc_source_mysql_01|worker] Ignoring await stop request for non-present connector jdbc_source_mysql_01 (org.apache.kafka.connect.runtime.Worker:444)
[2024-05-09 10:46:42,165] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2024-05-09 10:46:42,165] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2024-05-09 10:46:42,165] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 29 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', leaderUrl='http://127.0.1.1:8083/', offset=32, connectorIds=[], taskIds=[], revokedConnectorIds=[jdbc_source_mysql_01], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:46:42,172] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 32 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:46:42,173] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:46:42,173] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:46:42,173] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:46:42,175] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=30, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:46:42,177] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=30, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:46:42,177] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 30 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', leaderUrl='http://127.0.1.1:8083/', offset=32, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:46:42,177] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 32 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:46:42,177] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:46:44,175] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:46:44 +0000] "GET /connectors HTTP/1.1" 200 2 "-" "PostmanRuntime/7.37.0" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:46:58,533] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/test
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [test]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:46:58,534] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:370)
[2024-05-09 10:46:58,542] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_02 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2024-05-09 10:46:58,543] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:46:58,543] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:46:58,546] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=31, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:46:58,550] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=31, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:46:58,550] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 31 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', leaderUrl='http://127.0.1.1:8083/', offset=33, connectorIds=[jdbc_source_02], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:46:58,550] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 33 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:46:58,551] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector jdbc_source_02 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 10:46:58,551] INFO [jdbc_source_02|worker] Creating connector jdbc_source_02 of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 10:46:58,552] INFO [jdbc_source_02|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_02
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 10:46:58,552] INFO [jdbc_source_02|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_02
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 10:46:58,552] INFO [jdbc_source_02|worker] Instantiated connector jdbc_source_02 with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 10:46:58,553] INFO [jdbc_source_02|worker] Finished creating connector jdbc_source_02 (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 10:46:58,553] INFO [jdbc_source_02|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 10:46:58,553] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:46:58,553] INFO [jdbc_source_02|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3306/test
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [test]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:46:58,554] INFO [jdbc_source_02|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:46:58,554] INFO [jdbc_source_02|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:46:58,554] INFO [jdbc_source_02|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:46:58,554] INFO [jdbc_source_02|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:46:58,554] INFO [jdbc_source_02|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 10:46:58,555] INFO [jdbc_source_02|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/test
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:46:58,558] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:46:58 +0000] "POST /connectors HTTP/1.1" 201 401 "-" "PostmanRuntime/7.37.0" 65 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:47:08,557] INFO [jdbc_source_02|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/test
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:47:18,558] ERROR [jdbc_source_02|worker] WorkerConnector{id=jdbc_source_02} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/test
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/test
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:47:18,560] ERROR [jdbc_source_02|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'jdbc_source_02' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_02
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector jdbc_source_02 to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/test
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://localhost:3306/test
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:47:41,549] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql:// 127.0.0.1:3306/test
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [test]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:47:41,550] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:370)
[2024-05-09 10:47:41,555] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_01 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2024-05-09 10:47:41,556] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:47:41,556] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:47:41,557] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=32, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:47:41,558] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:47:41 +0000] "POST /connectors HTTP/1.1" 201 402 "-" "PostmanRuntime/7.37.0" 13 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:47:41,561] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=32, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:47:41,561] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 32 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', leaderUrl='http://127.0.1.1:8083/', offset=34, connectorIds=[jdbc_source_01, jdbc_source_02], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:47:41,562] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 34 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:47:41,562] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector jdbc_source_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 10:47:41,563] INFO [jdbc_source_01|worker] Creating connector jdbc_source_01 of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 10:47:41,563] INFO [jdbc_source_01|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 10:47:41,564] INFO [jdbc_source_01|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 10:47:41,564] INFO [jdbc_source_01|worker] Instantiated connector jdbc_source_01 with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 10:47:41,565] INFO [jdbc_source_01|worker] Finished creating connector jdbc_source_01 (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 10:47:41,565] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:47:41,565] INFO [jdbc_source_01|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 10:47:41,565] INFO [jdbc_source_01|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql:// 127.0.0.1:3306/test
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [test]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:47:41,565] INFO [jdbc_source_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:47:41,565] INFO [jdbc_source_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:47:41,565] INFO [jdbc_source_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:47:41,565] INFO [jdbc_source_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:47:41,565] INFO [jdbc_source_01|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 10:47:41,566] INFO [jdbc_source_01|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql:// 127.0.0.1:3306/test
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:47:45,925] INFO [AdminClient clientId=connect-cluster-shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:47:48,082] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:47:48 +0000] "GET /connectors HTTP/1.1" 200 35 "-" "PostmanRuntime/7.37.0" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:47:51,567] INFO [jdbc_source_01|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql:// 127.0.0.1:3306/test
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:47:54,736] INFO Successfully processed removal of connector 'jdbc_source_02' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1011)
[2024-05-09 10:47:54,736] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_02 config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2024-05-09 10:47:54,736] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector jdbc_source_02 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2024-05-09 10:47:54,736] INFO [jdbc_source_02|worker] Stopping connector jdbc_source_02 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:47:54,736] INFO [jdbc_source_02|worker] Scheduled shutdown for WorkerConnector{id=jdbc_source_02} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2024-05-09 10:47:54,737] INFO [jdbc_source_02|worker] Completed shutdown for WorkerConnector{id=jdbc_source_02} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2024-05-09 10:47:54,737] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:47:54 +0000] "DELETE /connectors/jdbc_source_02 HTTP/1.1" 204 0 "-" "PostmanRuntime/7.37.0" 12 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:47:54,738] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:47:54,738] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:47:54,740] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=33, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:47:54,743] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=33, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:47:54,743] INFO [jdbc_source_02|worker] Stopping connector jdbc_source_02 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:47:54,743] WARN [jdbc_source_02|worker] Ignoring stop request for unowned connector jdbc_source_02 (org.apache.kafka.connect.runtime.Worker:423)
[2024-05-09 10:47:54,744] WARN [jdbc_source_02|worker] Ignoring await stop request for non-present connector jdbc_source_02 (org.apache.kafka.connect.runtime.Worker:444)
[2024-05-09 10:47:54,744] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2024-05-09 10:47:54,744] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2024-05-09 10:47:54,744] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 33 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', leaderUrl='http://127.0.1.1:8083/', offset=36, connectorIds=[jdbc_source_01], taskIds=[], revokedConnectorIds=[jdbc_source_02], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:47:54,744] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 36 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:47:54,744] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:47:54,744] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:47:54,744] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:47:54,747] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=34, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:47:54,751] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=34, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:47:54,752] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 34 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', leaderUrl='http://127.0.1.1:8083/', offset=36, connectorIds=[jdbc_source_01], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:47:54,752] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 36 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:47:54,752] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:47:56,660] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://127.0.0.1:3306/test
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [test]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:47:56,661] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:370)
[2024-05-09 10:47:56,664] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:47:56 +0000] "POST /connectors HTTP/1.1" 409 70 "-" "PostmanRuntime/7.37.0" 8 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:48:01,568] ERROR [jdbc_source_01|worker] WorkerConnector{id=jdbc_source_01} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql:// 127.0.0.1:3306/test
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql:// 127.0.0.1:3306/test
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:48:01,570] ERROR [jdbc_source_01|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'jdbc_source_01' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_01
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector jdbc_source_01 to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql:// 127.0.0.1:3306/test
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql:// 127.0.0.1:3306/test
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:48:05,100] INFO Successfully processed removal of connector 'jdbc_source_01' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1011)
[2024-05-09 10:48:05,100] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_01 config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2371)
[2024-05-09 10:48:05,100] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector jdbc_source_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2024-05-09 10:48:05,100] INFO [jdbc_source_01|worker] Stopping connector jdbc_source_01 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:48:05,100] INFO [jdbc_source_01|worker] Scheduled shutdown for WorkerConnector{id=jdbc_source_01} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2024-05-09 10:48:05,101] INFO [jdbc_source_01|worker] Completed shutdown for WorkerConnector{id=jdbc_source_01} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2024-05-09 10:48:05,101] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:48:05 +0000] "DELETE /connectors/jdbc_source_01 HTTP/1.1" 204 0 "-" "PostmanRuntime/7.37.0" 6 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:48:05,101] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:48:05,101] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:48:05,104] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=35, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:48:05,106] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=35, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:48:05,107] INFO [jdbc_source_01|worker] Stopping connector jdbc_source_01 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 10:48:05,107] WARN [jdbc_source_01|worker] Ignoring stop request for unowned connector jdbc_source_01 (org.apache.kafka.connect.runtime.Worker:423)
[2024-05-09 10:48:05,107] WARN [jdbc_source_01|worker] Ignoring await stop request for non-present connector jdbc_source_01 (org.apache.kafka.connect.runtime.Worker:444)
[2024-05-09 10:48:05,107] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2667)
[2024-05-09 10:48:05,107] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2688)
[2024-05-09 10:48:05,108] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 35 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', leaderUrl='http://127.0.1.1:8083/', offset=38, connectorIds=[], taskIds=[], revokedConnectorIds=[jdbc_source_01], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:48:05,108] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 38 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:48:05,108] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:48:05,108] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:48:05,108] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:48:05,109] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=36, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:48:05,112] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=36, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:48:05,112] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 36 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', leaderUrl='http://127.0.1.1:8083/', offset=38, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:48:05,112] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 38 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:48:05,112] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:48:07,731] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://127.0.0.1:3306/test
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [test]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:48:07,731] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:370)
[2024-05-09 10:48:07,738] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_01 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2024-05-09 10:48:07,739] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 10:48:07,739] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 10:48:07,741] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:03:48:07 +0000] "POST /connectors HTTP/1.1" 201 401 "-" "PostmanRuntime/7.37.0" 13 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 10:48:07,741] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=37, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 10:48:07,745] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=37, memberId='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 10:48:07,745] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 37 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-feba3f26-4bfa-4079-9321-8efd3a9f392c', leaderUrl='http://127.0.1.1:8083/', offset=39, connectorIds=[jdbc_source_01], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 10:48:07,745] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 39 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 10:48:07,745] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector jdbc_source_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 10:48:07,746] INFO [jdbc_source_01|worker] Creating connector jdbc_source_01 of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 10:48:07,746] INFO [jdbc_source_01|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 10:48:07,746] INFO [jdbc_source_01|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 10:48:07,747] INFO [jdbc_source_01|worker] Instantiated connector jdbc_source_01 with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 10:48:07,747] INFO [jdbc_source_01|worker] Finished creating connector jdbc_source_01 (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 10:48:07,747] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 10:48:07,747] INFO [jdbc_source_01|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 10:48:07,747] INFO [jdbc_source_01|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://127.0.0.1:3306/test
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = id
	mode = incrementing
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [test]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = mysql_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 10:48:07,748] INFO [jdbc_source_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:48:07,748] INFO [jdbc_source_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:48:07,748] INFO [jdbc_source_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 10:48:07,748] INFO [jdbc_source_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 10:48:07,748] INFO [jdbc_source_01|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 10:48:07,749] INFO [jdbc_source_01|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://127.0.0.1:3306/test
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:48:17,750] INFO [jdbc_source_01|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://127.0.0.1:3306/test
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 10:48:27,751] ERROR [jdbc_source_01|worker] WorkerConnector{id=jdbc_source_01} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://127.0.0.1:3306/test
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://127.0.0.1:3306/test
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:48:27,752] ERROR [jdbc_source_01|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'jdbc_source_01' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_01
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector jdbc_source_01 to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://127.0.0.1:3306/test
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://127.0.0.1:3306/test
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 10:51:46,192] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:51:46,277] INFO [Producer clientId=connect-cluster-offsets] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:51:46,284] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:51:46,482] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:51:46,693] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:51:57,912] INFO [Producer clientId=connect-cluster-statuses] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:52:07,934] INFO [Producer clientId=connect-cluster-configs] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 10:57:46,145] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
