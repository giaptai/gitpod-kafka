[2024-05-09 09:09:46,788] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2024-05-09 09:09:46,792] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/macmkay/kafka/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 17.0.10, 17.0.10+7-Ubuntu-122.04.1
	jvm.classpath = /home/macmkay/kafka/bin/../libs/activation-1.1.1.jar:/home/macmkay/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/macmkay/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/macmkay/kafka/bin/../libs/audience-annotations-0.12.0.jar:/home/macmkay/kafka/bin/../libs/caffeine-2.9.3.jar:/home/macmkay/kafka/bin/../libs/checker-qual-3.19.0.jar:/home/macmkay/kafka/bin/../libs/commons-beanutils-1.9.4.jar:/home/macmkay/kafka/bin/../libs/commons-cli-1.4.jar:/home/macmkay/kafka/bin/../libs/commons-collections-3.2.2.jar:/home/macmkay/kafka/bin/../libs/commons-digester-2.1.jar:/home/macmkay/kafka/bin/../libs/commons-io-2.11.0.jar:/home/macmkay/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/macmkay/kafka/bin/../libs/commons-logging-1.2.jar:/home/macmkay/kafka/bin/../libs/commons-validator-1.7.jar:/home/macmkay/kafka/bin/../libs/connect-api-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-basic-auth-extension-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-json-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-mirror-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-mirror-client-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-runtime-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-transforms-3.7.0.jar:/home/macmkay/kafka/bin/../libs/error_prone_annotations-2.10.0.jar:/home/macmkay/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/macmkay/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/macmkay/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/macmkay/kafka/bin/../libs/jackson-annotations-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-core-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-databind-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-dataformat-csv-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-datatype-jdk8-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-jaxrs-base-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-jaxrs-json-provider-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-module-jaxb-annotations-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-module-scala_2.13-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jakarta.activation-api-1.2.2.jar:/home/macmkay/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/macmkay/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/macmkay/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/macmkay/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/macmkay/kafka/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/home/macmkay/kafka/bin/../libs/javassist-3.29.2-GA.jar:/home/macmkay/kafka/bin/../libs/javax.activation-api-1.2.0.jar:/home/macmkay/kafka/bin/../libs/javax.annotation-api-1.3.2.jar:/home/macmkay/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/macmkay/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/macmkay/kafka/bin/../libs/jaxb-api-2.3.1.jar:/home/macmkay/kafka/bin/../libs/jersey-client-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-common-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-container-servlet-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-hk2-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-server-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jetty-client-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-continuation-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-http-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-io-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-security-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-server-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-servlet-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-servlets-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-util-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-util-ajax-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jline-3.22.0.jar:/home/macmkay/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/macmkay/kafka/bin/../libs/jose4j-0.9.4.jar:/home/macmkay/kafka/bin/../libs/jsr305-3.0.2.jar:/home/macmkay/kafka/bin/../libs/kafka-clients-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-group-coordinator-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-log4j-appender-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-metadata-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-raft-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-server-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-server-common-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-shell-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-storage-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-storage-api-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-streams-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-streams-examples-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-streams-scala_2.13-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-streams-test-utils-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-tools-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-tools-api-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka_2.13-3.7.0.jar:/home/macmkay/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/macmkay/kafka/bin/../libs/maven-artifact-3.8.8.jar:/home/macmkay/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/macmkay/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/macmkay/kafka/bin/../libs/netty-buffer-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-codec-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-common-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-handler-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-resolver-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-transport-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-transport-classes-epoll-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-transport-native-epoll-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-transport-native-unix-common-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/home/macmkay/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/macmkay/kafka/bin/../libs/paranamer-2.8.jar:/home/macmkay/kafka/bin/../libs/pcollections-4.0.1.jar:/home/macmkay/kafka/bin/../libs/plexus-utils-3.3.1.jar:/home/macmkay/kafka/bin/../libs/protobuf-java-3.23.4.jar:/home/macmkay/kafka/bin/../libs/reflections-0.10.2.jar:/home/macmkay/kafka/bin/../libs/reload4j-1.2.25.jar:/home/macmkay/kafka/bin/../libs/rocksdbjni-7.9.2.jar:/home/macmkay/kafka/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/home/macmkay/kafka/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/home/macmkay/kafka/bin/../libs/scala-library-2.13.12.jar:/home/macmkay/kafka/bin/../libs/scala-logging_2.13-3.9.4.jar:/home/macmkay/kafka/bin/../libs/scala-reflect-2.13.12.jar:/home/macmkay/kafka/bin/../libs/slf4j-api-1.7.36.jar:/home/macmkay/kafka/bin/../libs/slf4j-reload4j-1.7.36.jar:/home/macmkay/kafka/bin/../libs/snappy-java-1.1.10.5.jar:/home/macmkay/kafka/bin/../libs/swagger-annotations-2.2.8.jar:/home/macmkay/kafka/bin/../libs/trogdor-3.7.0.jar:/home/macmkay/kafka/bin/../libs/zookeeper-3.8.3.jar:/home/macmkay/kafka/bin/../libs/zookeeper-jute-3.8.3.jar:/home/macmkay/kafka/bin/../libs/zstd-jni-1.5.5-6.jar
	os.spec = Linux, amd64, 5.15.146.1-microsoft-standard-WSL2
	os.vcpus = 12
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2024-05-09 09:09:46,793] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2024-05-09 09:09:46,812] INFO Loading plugin from: /home/macmkay/kafka/./libs/connect-file-3.7.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:09:46,964] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/./libs/connect-file-3.7.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:09:46,965] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:09:46,972] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@1dbd16a6 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:09:46,973] INFO Scanning plugins with ServiceLoaderScanner took 162 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2024-05-09 09:09:46,974] INFO Loading plugin from: /home/macmkay/kafka/./libs/connect-file-3.7.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:09:47,024] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/./libs/connect-file-3.7.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:09:47,024] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:09:48,385] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@1dbd16a6 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:09:48,386] INFO Scanning plugins with ReflectionScanner took 1412 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2024-05-09 09:09:48,390] WARN All plugins have ServiceLoader manifests, consider reconfiguring plugin.discovery=service_load (org.apache.kafka.connect.runtime.isolation.Plugins:105)
[2024-05-09 09:09:48,391] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,392] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,392] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,392] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,392] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,392] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,392] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,393] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,393] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,393] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,393] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,393] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,394] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,394] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,394] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,394] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,394] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,394] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,395] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,395] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,395] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,395] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,396] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,396] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,396] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,396] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,396] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,396] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,397] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,397] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,397] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,397] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,397] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,397] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,398] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,398] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,398] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,398] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,398] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,399] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,399] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,399] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,399] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,399] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,399] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,399] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,400] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,400] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,400] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,400] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,401] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:09:48,403] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,404] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,404] INFO Added alias 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,404] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,404] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,404] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,404] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,404] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,404] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,404] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,405] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,405] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,405] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,405] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,405] INFO Added alias 'FileStreamSinkConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,405] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,405] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,405] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,405] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,406] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,406] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,406] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,406] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,406] INFO Added alias 'FileStreamSourceConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,406] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,406] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,407] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,407] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,407] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,407] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,407] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,407] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,408] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,408] INFO Added alias 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,408] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,408] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,408] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,408] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,408] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,408] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,408] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,409] INFO Added alias 'ByteArrayConverter' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,409] INFO Added alias 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,409] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,409] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,409] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,409] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,409] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,409] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,410] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,410] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,410] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:09:48,458] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [./libs/connect-file-3.7.0.jar]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = SASL_PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:370)
[2024-05-09 09:09:48,459] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:283)
[2024-05-09 09:09:48,462] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-05-09 09:09:48,525] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin:61)
[2024-05-09 09:09:48,589] INFO These configurations '[producer.sasl.jaas.config, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, status.storage.topic, group.id, plugin.path, consumer.sasl.mechanism, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-05-09 09:09:48,590] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:09:48,590] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:09:48,590] INFO Kafka startTimeMs: 1715220588590 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:09:48,845] INFO Kafka cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.connect.runtime.WorkerConfig:300)
[2024-05-09 09:09:48,846] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 09:09:48,850] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 09:09:48,851] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:09:48,851] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 09:09:48,855] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:370)
[2024-05-09 09:09:48,861] INFO Logging initialized @2364ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2024-05-09 09:09:48,889] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:111)
[2024-05-09 09:09:48,890] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:182)
[2024-05-09 09:09:48,931] INFO jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 17.0.10+7-Ubuntu-122.04.1 (org.eclipse.jetty.server.Server:375)
[2024-05-09 09:09:48,949] INFO Started http_8083@58a2b917{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2024-05-09 09:09:48,949] INFO Started @2452ms (org.eclipse.jetty.server.Server:415)
[2024-05-09 09:09:48,965] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:406)
[2024-05-09 09:09:48,966] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:202)
[2024-05-09 09:09:48,967] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:406)
[2024-05-09 09:09:48,967] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:205)
[2024-05-09 09:09:48,967] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:406)
[2024-05-09 09:09:48,967] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2024-05-09 09:09:48,972] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:370)
[2024-05-09 09:09:48,983] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:09:48,983] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:09:48,984] INFO Kafka startTimeMs: 1715220588983 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:09:48,989] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:370)
[2024-05-09 09:09:48,990] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:370)
[2024-05-09 09:09:49,005] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:406)
[2024-05-09 09:09:49,013] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin:61)
[2024-05-09 09:09:49,030] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:09:49,030] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:09:49,030] INFO Kafka startTimeMs: 1715220589030 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:09:49,033] INFO Kafka Connect worker initialization took 2243ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2024-05-09 09:09:49,033] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2024-05-09 09:09:49,036] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:209)
[2024-05-09 09:09:49,036] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:369)
[2024-05-09 09:09:49,038] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:231)
[2024-05-09 09:09:49,038] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:240)
[2024-05-09 09:09:49,038] INFO Starting KafkaBasedLog with topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2024-05-09 09:09:49,039] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-05-09 09:09:49,042] INFO These configurations '[producer.sasl.jaas.config, group.id, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-05-09 09:09:49,042] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:09:49,042] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:09:49,043] INFO Kafka startTimeMs: 1715220589042 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:09:49,072] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:227)
[2024-05-09 09:09:49,105] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2024-05-09 09:09:49,105] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2024-05-09 09:09:49,106] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2024-05-09 09:09:49,133] INFO Created topic (name=connect-offsets, numPartitions=25, replicationFactor=1, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at localhost:9092 (org.apache.kafka.connect.util.TopicAdmin:445)
[2024-05-09 09:09:49,140] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-05-09 09:09:49,161] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 09:09:49,187] INFO These configurations '[producer.sasl.jaas.config, group.id, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-05-09 09:09:49,188] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:09:49,188] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:09:49,188] INFO Kafka startTimeMs: 1715220589188 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:09:49,197] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-05-09 09:09:49,208] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 09:09:49,210] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 09:09:49,250] INFO These configurations '[producer.sasl.jaas.config, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-05-09 09:09:49,250] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:09:49,250] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:09:49,250] INFO Kafka startTimeMs: 1715220589250 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:09:49,266] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 09:09:49,291] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-17, connect-offsets-20, connect-offsets-11, connect-offsets-23, connect-offsets-14, connect-offsets-5, connect-offsets-0, connect-offsets-8, connect-offsets-7, connect-offsets-4, connect-offsets-1, connect-offsets-10, connect-offsets-13, connect-offsets-24, connect-offsets-21, connect-offsets-16, connect-offsets-3, connect-offsets-9, connect-offsets-15, connect-offsets-18, connect-offsets-19, connect-offsets-22, connect-offsets-6, connect-offsets-2, connect-offsets-12 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2024-05-09 09:09:49,297] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,298] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,299] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,299] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,299] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,299] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,299] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,300] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,300] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,300] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,300] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,300] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,300] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,300] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,300] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,301] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,301] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,301] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,301] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,304] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,304] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,304] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,304] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,304] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,305] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,561] INFO Started o.e.j.s.ServletContextHandler@39f5b723{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2024-05-09 09:09:49,562] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:302)
[2024-05-09 09:09:49,562] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2024-05-09 09:09:49,638] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,639] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,639] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,639] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,639] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,640] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,640] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,640] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,640] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,640] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,640] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,640] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,640] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,641] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,641] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,641] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,641] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,641] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,641] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,642] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,642] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,642] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,642] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,642] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,642] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,643] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2024-05-09 09:09:49,643] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2024-05-09 09:09:49,643] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:257)
[2024-05-09 09:09:49,644] INFO Worker started (org.apache.kafka.connect.runtime.Worker:241)
[2024-05-09 09:09:49,644] INFO Starting KafkaBasedLog with topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2024-05-09 09:09:49,680] INFO Created topic (name=connect-status, numPartitions=5, replicationFactor=1, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at localhost:9092 (org.apache.kafka.connect.util.TopicAdmin:445)
[2024-05-09 09:09:49,681] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-05-09 09:09:49,681] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 09:09:49,688] INFO These configurations '[producer.sasl.jaas.config, group.id, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-05-09 09:09:49,688] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:09:49,688] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:09:49,688] INFO Kafka startTimeMs: 1715220589688 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:09:49,690] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-05-09 09:09:49,691] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 09:09:49,698] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 09:09:49,698] INFO These configurations '[producer.sasl.jaas.config, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-05-09 09:09:49,699] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:09:49,699] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:09:49,699] INFO Kafka startTimeMs: 1715220589699 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:09:49,707] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 09:09:49,709] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-1, connect-status-3, connect-status-2, connect-status-0, connect-status-4 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2024-05-09 09:09:49,710] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,710] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,710] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,710] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,710] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,841] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,841] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,841] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,841] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,842] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,842] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2024-05-09 09:09:49,842] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2024-05-09 09:09:49,845] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:378)
[2024-05-09 09:09:49,845] INFO Starting KafkaBasedLog with topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2024-05-09 09:09:49,880] INFO Created topic (name=connect-configs, numPartitions=1, replicationFactor=1, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at localhost:9092 (org.apache.kafka.connect.util.TopicAdmin:445)
[2024-05-09 09:09:49,881] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-05-09 09:09:49,881] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 09:09:49,886] INFO These configurations '[producer.sasl.jaas.config, group.id, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-05-09 09:09:49,887] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:09:49,887] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:09:49,887] INFO Kafka startTimeMs: 1715220589887 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:09:49,888] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-05-09 09:09:49,889] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 09:09:49,892] INFO [Producer clientId=connect-cluster-configs] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 09:09:49,894] INFO These configurations '[producer.sasl.jaas.config, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-05-09 09:09:49,894] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:09:49,894] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:09:49,894] INFO Kafka startTimeMs: 1715220589894 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:09:49,899] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 09:09:49,900] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2024-05-09 09:09:49,900] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:09:49,909] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:09:49,909] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2024-05-09 09:09:49,909] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2024-05-09 09:09:49,909] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:402)
[2024-05-09 09:09:49,909] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:376)
[2024-05-09 09:09:49,917] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 09:09:50,047] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2024-05-09 09:09:50,049] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 09:09:50,049] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 09:09:50,061] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Group coordinator localhost:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:999)
[2024-05-09 09:09:50,061] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Requesting disconnect from last known coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1012)
[2024-05-09 09:09:50,061] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:694)
[2024-05-09 09:09:50,061] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1102)
[2024-05-09 09:09:50,162] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Client requested disconnect from node 2147483646 (org.apache.kafka.clients.NetworkClient:333)
[2024-05-09 09:09:50,165] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2024-05-09 09:09:50,165] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Group coordinator localhost:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:999)
[2024-05-09 09:09:50,165] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Requesting disconnect from last known coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1012)
[2024-05-09 09:09:50,256] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2024-05-09 09:09:50,257] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 09:09:50,263] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Group coordinator localhost:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:999)
[2024-05-09 09:09:50,263] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Requesting disconnect from last known coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1012)
[2024-05-09 09:09:50,263] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:694)
[2024-05-09 09:09:50,263] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1102)
[2024-05-09 09:09:50,364] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Client requested disconnect from node 2147483646 (org.apache.kafka.clients.NetworkClient:333)
[2024-05-09 09:09:50,366] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2024-05-09 09:09:50,366] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Group coordinator localhost:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:999)
[2024-05-09 09:09:50,367] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Requesting disconnect from last known coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1012)
[2024-05-09 09:09:50,484] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2024-05-09 09:09:50,485] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 09:09:50,496] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 09:09:53,508] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=1, memberId='connect-127.0.1.1:8083-ea5db1cd-151d-4093-87f1-00b7b4ee4115', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 09:09:53,537] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=1, memberId='connect-127.0.1.1:8083-ea5db1cd-151d-4093-87f1-00b7b4ee4115', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 09:09:53,538] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 1 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-ea5db1cd-151d-4093-87f1-00b7b4ee4115', leaderUrl='http://127.0.1.1:8083/', offset=-1, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 09:09:53,539] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset -1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 09:09:53,539] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 09:09:53,587] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2442)
[2024-05-09 09:14:49,144] INFO [AdminClient clientId=connect-cluster-shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:18:49,406] INFO [Producer clientId=connect-cluster-offsets] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:18:49,461] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:18:49,961] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:18:49,964] INFO [Producer clientId=connect-cluster-statuses] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:18:49,998] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:18:50,122] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:18:50,143] INFO [Producer clientId=connect-cluster-configs] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:19:49,231] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:24:49,417] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:28:49,615] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:28:49,738] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:28:50,286] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:29:49,592] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:34:49,795] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:38:41,304] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2024-05-09 09:38:41,305] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:348)
[2024-05-09 09:38:41,322] INFO Stopped http_8083@58a2b917{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2024-05-09 09:38:41,323] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2024-05-09 09:38:41,333] INFO Stopped o.e.j.s.ServletContextHandler@39f5b723{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler:1159)
[2024-05-09 09:38:41,334] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:377)
[2024-05-09 09:38:41,334] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:831)
[2024-05-09 09:38:41,334] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:794)
[2024-05-09 09:38:41,335] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Member connect-127.0.1.1:8083-ea5db1cd-151d-4093-87f1-00b7b4ee4115 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: null) due to the consumer is being closed (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1163)
[2024-05-09 09:38:41,336] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1055)
[2024-05-09 09:38:41,336] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1140)
[2024-05-09 09:38:41,336] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 09:38:41,336] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:38:41,337] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 09:38:41,339] INFO App info kafka.connect for connect-127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 09:38:41,339] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:292)
[2024-05-09 09:38:41,340] INFO [Producer clientId=connect-cluster-statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2024-05-09 09:38:41,345] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 09:38:41,345] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:38:41,345] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:38:41,345] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 09:38:41,347] INFO App info kafka.producer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 09:38:41,349] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2024-05-09 09:38:41,350] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2024-05-09 09:38:41,787] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 09:38:41,787] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:38:41,787] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:38:41,787] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 09:38:41,791] INFO App info kafka.consumer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 09:38:41,791] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2024-05-09 09:38:41,792] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:407)
[2024-05-09 09:38:41,792] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:292)
[2024-05-09 09:38:41,793] INFO [Producer clientId=connect-cluster-configs] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2024-05-09 09:38:41,796] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 09:38:41,796] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:38:41,796] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:38:41,796] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 09:38:41,797] INFO App info kafka.producer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 09:38:41,797] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2024-05-09 09:38:41,797] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2024-05-09 09:38:42,005] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 09:38:42,005] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:38:42,006] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:38:42,006] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 09:38:42,008] INFO App info kafka.consumer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 09:38:42,008] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2024-05-09 09:38:42,008] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:413)
[2024-05-09 09:38:42,008] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:248)
[2024-05-09 09:38:42,009] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:269)
[2024-05-09 09:38:42,009] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:292)
[2024-05-09 09:38:42,009] INFO [Producer clientId=connect-cluster-offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2024-05-09 09:38:42,012] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 09:38:42,012] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:38:42,012] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:38:42,012] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 09:38:42,013] INFO App info kafka.producer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 09:38:42,013] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2024-05-09 09:38:42,013] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2024-05-09 09:38:42,306] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 09:38:42,306] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:38:42,307] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:38:42,307] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 09:38:42,310] INFO App info kafka.consumer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 09:38:42,310] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2024-05-09 09:38:42,310] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:277)
[2024-05-09 09:38:42,310] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 09:38:42,310] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:38:42,310] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 09:38:42,310] INFO App info kafka.connect for 127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 09:38:42,311] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:269)
[2024-05-09 09:38:42,312] INFO App info kafka.admin.client for connect-cluster-shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 09:38:42,314] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 09:38:42,314] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:38:42,314] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 09:38:42,314] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:386)
[2024-05-09 09:38:42,314] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:838)
[2024-05-09 09:38:42,314] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2024-05-09 09:38:46,179] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2024-05-09 09:38:46,183] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/macmkay/kafka/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 17.0.10, 17.0.10+7-Ubuntu-122.04.1
	jvm.classpath = /home/macmkay/kafka/bin/../libs/activation-1.1.1.jar:/home/macmkay/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/macmkay/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/macmkay/kafka/bin/../libs/audience-annotations-0.12.0.jar:/home/macmkay/kafka/bin/../libs/caffeine-2.9.3.jar:/home/macmkay/kafka/bin/../libs/checker-qual-3.19.0.jar:/home/macmkay/kafka/bin/../libs/commons-beanutils-1.9.4.jar:/home/macmkay/kafka/bin/../libs/commons-cli-1.4.jar:/home/macmkay/kafka/bin/../libs/commons-collections-3.2.2.jar:/home/macmkay/kafka/bin/../libs/commons-digester-2.1.jar:/home/macmkay/kafka/bin/../libs/commons-io-2.11.0.jar:/home/macmkay/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/macmkay/kafka/bin/../libs/commons-logging-1.2.jar:/home/macmkay/kafka/bin/../libs/commons-validator-1.7.jar:/home/macmkay/kafka/bin/../libs/connect-api-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-basic-auth-extension-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-json-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-mirror-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-mirror-client-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-runtime-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-transforms-3.7.0.jar:/home/macmkay/kafka/bin/../libs/error_prone_annotations-2.10.0.jar:/home/macmkay/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/macmkay/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/macmkay/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/macmkay/kafka/bin/../libs/jackson-annotations-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-core-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-databind-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-dataformat-csv-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-datatype-jdk8-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-jaxrs-base-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-jaxrs-json-provider-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-module-jaxb-annotations-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-module-scala_2.13-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jakarta.activation-api-1.2.2.jar:/home/macmkay/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/macmkay/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/macmkay/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/macmkay/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/macmkay/kafka/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/home/macmkay/kafka/bin/../libs/javassist-3.29.2-GA.jar:/home/macmkay/kafka/bin/../libs/javax.activation-api-1.2.0.jar:/home/macmkay/kafka/bin/../libs/javax.annotation-api-1.3.2.jar:/home/macmkay/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/macmkay/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/macmkay/kafka/bin/../libs/jaxb-api-2.3.1.jar:/home/macmkay/kafka/bin/../libs/jersey-client-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-common-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-container-servlet-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-hk2-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-server-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jetty-client-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-continuation-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-http-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-io-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-security-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-server-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-servlet-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-servlets-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-util-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-util-ajax-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jline-3.22.0.jar:/home/macmkay/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/macmkay/kafka/bin/../libs/jose4j-0.9.4.jar:/home/macmkay/kafka/bin/../libs/jsr305-3.0.2.jar:/home/macmkay/kafka/bin/../libs/kafka-clients-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-group-coordinator-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-log4j-appender-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-metadata-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-raft-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-server-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-server-common-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-shell-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-storage-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-storage-api-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-streams-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-streams-examples-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-streams-scala_2.13-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-streams-test-utils-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-tools-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-tools-api-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka_2.13-3.7.0.jar:/home/macmkay/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/macmkay/kafka/bin/../libs/maven-artifact-3.8.8.jar:/home/macmkay/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/macmkay/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/macmkay/kafka/bin/../libs/netty-buffer-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-codec-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-common-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-handler-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-resolver-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-transport-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-transport-classes-epoll-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-transport-native-epoll-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-transport-native-unix-common-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/home/macmkay/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/macmkay/kafka/bin/../libs/paranamer-2.8.jar:/home/macmkay/kafka/bin/../libs/pcollections-4.0.1.jar:/home/macmkay/kafka/bin/../libs/plexus-utils-3.3.1.jar:/home/macmkay/kafka/bin/../libs/protobuf-java-3.23.4.jar:/home/macmkay/kafka/bin/../libs/reflections-0.10.2.jar:/home/macmkay/kafka/bin/../libs/reload4j-1.2.25.jar:/home/macmkay/kafka/bin/../libs/rocksdbjni-7.9.2.jar:/home/macmkay/kafka/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/home/macmkay/kafka/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/home/macmkay/kafka/bin/../libs/scala-library-2.13.12.jar:/home/macmkay/kafka/bin/../libs/scala-logging_2.13-3.9.4.jar:/home/macmkay/kafka/bin/../libs/scala-reflect-2.13.12.jar:/home/macmkay/kafka/bin/../libs/slf4j-api-1.7.36.jar:/home/macmkay/kafka/bin/../libs/slf4j-reload4j-1.7.36.jar:/home/macmkay/kafka/bin/../libs/snappy-java-1.1.10.5.jar:/home/macmkay/kafka/bin/../libs/swagger-annotations-2.2.8.jar:/home/macmkay/kafka/bin/../libs/trogdor-3.7.0.jar:/home/macmkay/kafka/bin/../libs/zookeeper-3.8.3.jar:/home/macmkay/kafka/bin/../libs/zookeeper-jute-3.8.3.jar:/home/macmkay/kafka/bin/../libs/zstd-jni-1.5.5-6.jar
	os.spec = Linux, amd64, 5.15.146.1-microsoft-standard-WSL2
	os.vcpus = 12
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2024-05-09 09:38:46,184] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2024-05-09 09:38:46,192] ERROR Could not get listing for plugin path: confluentinc-kafka-connect-jdbc/lib. Ignoring. (org.apache.kafka.connect.runtime.isolation.PluginUtils:227)
java.io.FileNotFoundException: /home/macmkay/kafka/confluentinc-kafka-connect-jdbc/lib
	at org.apache.kafka.connect.runtime.isolation.PluginUtils.pluginLocations(PluginUtils.java:214)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:72)
	at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:64)
	at org.apache.kafka.connect.cli.AbstractConnectCli.startConnect(AbstractConnectCli.java:121)
	at org.apache.kafka.connect.cli.AbstractConnectCli.run(AbstractConnectCli.java:94)
	at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:116)
[2024-05-09 09:38:46,201] INFO Loading plugin from: /home/macmkay/kafka/./libs/connect-file-3.7.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:38:46,356] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/./libs/connect-file-3.7.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:38:46,357] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:38:46,364] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@1dbd16a6 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:38:46,365] INFO Scanning plugins with ServiceLoaderScanner took 164 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2024-05-09 09:38:46,366] INFO Loading plugin from: /home/macmkay/kafka/./libs/connect-file-3.7.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:38:46,404] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/./libs/connect-file-3.7.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:38:46,404] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:38:47,742] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@1dbd16a6 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:38:47,743] INFO Scanning plugins with ReflectionScanner took 1376 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2024-05-09 09:38:47,745] WARN All plugins have ServiceLoader manifests, consider reconfiguring plugin.discovery=service_load (org.apache.kafka.connect.runtime.isolation.Plugins:105)
[2024-05-09 09:38:47,747] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,747] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,747] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,747] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,747] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,747] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,747] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,748] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,748] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,748] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,748] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,748] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,748] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,748] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,748] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,748] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,748] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,749] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,749] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,749] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,749] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,749] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,749] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,749] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,749] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,749] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,749] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,749] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,750] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,750] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,750] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,750] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,750] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,750] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,750] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,750] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,750] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,750] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,751] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,751] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,751] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,751] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,751] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,751] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,751] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,751] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,751] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,752] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,752] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,752] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,752] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:38:47,754] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,754] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,754] INFO Added alias 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,754] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,755] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,755] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,755] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,755] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,755] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,755] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,755] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,755] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,755] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,755] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,755] INFO Added alias 'FileStreamSinkConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,755] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,755] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,756] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,756] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,756] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,756] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,756] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,756] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,756] INFO Added alias 'FileStreamSourceConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,756] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,756] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,756] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,756] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,757] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,757] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,757] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,757] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,757] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,757] INFO Added alias 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,757] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,757] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,757] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,757] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,757] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,757] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,758] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,758] INFO Added alias 'ByteArrayConverter' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,758] INFO Added alias 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,758] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,758] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,758] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,758] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,758] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,758] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,758] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,758] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,758] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:38:47,798] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [./libs/connect-file-3.7.0.jar, confluentinc-kafka-connect-jdbc/lib]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = SASL_PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:370)
[2024-05-09 09:38:47,800] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:283)
[2024-05-09 09:38:47,802] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-05-09 09:38:47,860] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin:61)
[2024-05-09 09:38:47,915] INFO These configurations '[producer.sasl.jaas.config, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, status.storage.topic, group.id, plugin.path, consumer.sasl.mechanism, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-05-09 09:38:47,916] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:38:47,916] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:38:47,916] INFO Kafka startTimeMs: 1715222327916 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:38:48,135] INFO Kafka cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.connect.runtime.WorkerConfig:300)
[2024-05-09 09:38:48,136] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 09:38:48,140] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 09:38:48,141] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:38:48,141] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 09:38:48,144] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:370)
[2024-05-09 09:38:48,151] INFO Logging initialized @2311ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2024-05-09 09:38:48,177] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:111)
[2024-05-09 09:38:48,177] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:182)
[2024-05-09 09:38:48,196] INFO jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 17.0.10+7-Ubuntu-122.04.1 (org.eclipse.jetty.server.Server:375)
[2024-05-09 09:38:48,249] INFO Started http_8083@4ee25d80{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2024-05-09 09:38:48,250] INFO Started @2410ms (org.eclipse.jetty.server.Server:415)
[2024-05-09 09:38:48,268] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:406)
[2024-05-09 09:38:48,268] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:202)
[2024-05-09 09:38:48,268] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:406)
[2024-05-09 09:38:48,269] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:205)
[2024-05-09 09:38:48,269] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:406)
[2024-05-09 09:38:48,269] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2024-05-09 09:38:48,274] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:370)
[2024-05-09 09:38:48,287] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:38:48,287] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:38:48,287] INFO Kafka startTimeMs: 1715222328287 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:38:48,292] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:370)
[2024-05-09 09:38:48,293] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:370)
[2024-05-09 09:38:48,310] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:406)
[2024-05-09 09:38:48,319] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin:61)
[2024-05-09 09:38:48,335] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:38:48,335] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:38:48,335] INFO Kafka startTimeMs: 1715222328335 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:38:48,338] INFO Kafka Connect worker initialization took 2157ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2024-05-09 09:38:48,338] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2024-05-09 09:38:48,341] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:209)
[2024-05-09 09:38:48,341] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:369)
[2024-05-09 09:38:48,343] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:231)
[2024-05-09 09:38:48,343] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:240)
[2024-05-09 09:38:48,343] INFO Starting KafkaBasedLog with topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2024-05-09 09:38:48,344] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-05-09 09:38:48,347] INFO These configurations '[producer.sasl.jaas.config, group.id, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-05-09 09:38:48,347] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:38:48,347] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:38:48,348] INFO Kafka startTimeMs: 1715222328347 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:38:48,379] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:227)
[2024-05-09 09:38:48,398] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-05-09 09:38:48,414] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2024-05-09 09:38:48,414] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2024-05-09 09:38:48,415] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2024-05-09 09:38:48,420] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 09:38:48,444] INFO These configurations '[producer.sasl.jaas.config, group.id, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-05-09 09:38:48,444] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:38:48,444] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:38:48,444] INFO Kafka startTimeMs: 1715222328444 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:38:48,452] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-05-09 09:38:48,457] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 09:38:48,465] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 09:38:48,493] INFO These configurations '[producer.sasl.jaas.config, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-05-09 09:38:48,493] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:38:48,493] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:38:48,493] INFO Kafka startTimeMs: 1715222328493 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:38:48,505] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 09:38:48,510] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-17, connect-offsets-20, connect-offsets-11, connect-offsets-23, connect-offsets-14, connect-offsets-5, connect-offsets-0, connect-offsets-8, connect-offsets-7, connect-offsets-4, connect-offsets-1, connect-offsets-10, connect-offsets-13, connect-offsets-24, connect-offsets-21, connect-offsets-16, connect-offsets-3, connect-offsets-9, connect-offsets-15, connect-offsets-18, connect-offsets-19, connect-offsets-22, connect-offsets-6, connect-offsets-2, connect-offsets-12 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2024-05-09 09:38:48,513] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,513] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,513] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,514] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,514] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,514] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,514] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,514] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,514] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,514] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,514] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,514] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,514] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,514] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,515] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,515] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,515] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,515] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,515] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,515] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,515] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,515] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,515] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,516] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,516] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,573] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,574] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,574] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,574] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,574] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,575] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,575] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,575] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,575] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,575] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,575] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,575] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,576] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,576] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,576] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,576] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,576] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,576] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,577] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,577] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,577] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,577] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,577] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,578] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,578] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,579] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2024-05-09 09:38:48,579] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2024-05-09 09:38:48,579] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:257)
[2024-05-09 09:38:48,580] INFO Worker started (org.apache.kafka.connect.runtime.Worker:241)
[2024-05-09 09:38:48,581] INFO Starting KafkaBasedLog with topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2024-05-09 09:38:48,610] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-05-09 09:38:48,611] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 09:38:48,615] INFO These configurations '[producer.sasl.jaas.config, group.id, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-05-09 09:38:48,616] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:38:48,616] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:38:48,616] INFO Kafka startTimeMs: 1715222328616 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:38:48,617] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-05-09 09:38:48,617] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 09:38:48,623] INFO These configurations '[producer.sasl.jaas.config, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-05-09 09:38:48,623] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:38:48,623] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:38:48,624] INFO Kafka startTimeMs: 1715222328623 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:38:48,624] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 09:38:48,629] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 09:38:48,630] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-1, connect-status-3, connect-status-2, connect-status-0, connect-status-4 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2024-05-09 09:38:48,630] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,630] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,630] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,631] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,631] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,642] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,642] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,642] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,642] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,642] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,643] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2024-05-09 09:38:48,643] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2024-05-09 09:38:48,645] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:378)
[2024-05-09 09:38:48,645] INFO Starting KafkaBasedLog with topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2024-05-09 09:38:48,652] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-05-09 09:38:48,653] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 09:38:48,659] INFO These configurations '[producer.sasl.jaas.config, group.id, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-05-09 09:38:48,660] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:38:48,660] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:38:48,660] INFO Kafka startTimeMs: 1715222328660 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:38:48,661] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-05-09 09:38:48,661] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 09:38:48,666] INFO [Producer clientId=connect-cluster-configs] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 09:38:48,667] INFO These configurations '[producer.sasl.jaas.config, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-05-09 09:38:48,668] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:38:48,668] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:38:48,668] INFO Kafka startTimeMs: 1715222328668 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:38:48,674] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 09:38:48,675] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2024-05-09 09:38:48,675] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:38:48,687] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:38:48,720] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2024-05-09 09:38:48,720] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2024-05-09 09:38:48,720] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:402)
[2024-05-09 09:38:48,721] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:376)
[2024-05-09 09:38:48,730] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 09:38:48,731] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2024-05-09 09:38:48,733] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 09:38:48,733] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 09:38:48,743] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 09:38:48,835] INFO Started o.e.j.s.ServletContextHandler@3135bf25{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2024-05-09 09:38:48,835] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:302)
[2024-05-09 09:38:48,835] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2024-05-09 09:38:51,747] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=3, memberId='connect-127.0.1.1:8083-d39fe241-374a-45cd-ab3b-9f2c84d40d2e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 09:38:51,762] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=3, memberId='connect-127.0.1.1:8083-d39fe241-374a-45cd-ab3b-9f2c84d40d2e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 09:38:51,762] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 3 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-d39fe241-374a-45cd-ab3b-9f2c84d40d2e', leaderUrl='http://127.0.1.1:8083/', offset=1, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 09:38:51,762] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1753)
[2024-05-09 09:38:51,762] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Current config state offset -1 is behind group assignment 1, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1826)
[2024-05-09 09:38:51,765] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1853)
[2024-05-09 09:38:51,765] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 09:38:51,765] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 09:41:21,493] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2024-05-09 09:41:21,494] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:348)
[2024-05-09 09:41:21,505] INFO Stopped http_8083@4ee25d80{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2024-05-09 09:41:21,506] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2024-05-09 09:41:21,506] INFO Stopped o.e.j.s.ServletContextHandler@3135bf25{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler:1159)
[2024-05-09 09:41:21,508] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:377)
[2024-05-09 09:41:21,508] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:831)
[2024-05-09 09:41:21,509] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:794)
[2024-05-09 09:41:21,509] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Member connect-127.0.1.1:8083-d39fe241-374a-45cd-ab3b-9f2c84d40d2e sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: null) due to the consumer is being closed (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1163)
[2024-05-09 09:41:21,510] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1055)
[2024-05-09 09:41:21,510] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1140)
[2024-05-09 09:41:21,510] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 09:41:21,510] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:41:21,511] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 09:41:21,512] INFO App info kafka.connect for connect-127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 09:41:21,512] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:292)
[2024-05-09 09:41:21,514] INFO [Producer clientId=connect-cluster-statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2024-05-09 09:41:21,517] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 09:41:21,517] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:41:21,517] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:41:21,517] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 09:41:21,517] INFO App info kafka.producer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 09:41:21,519] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2024-05-09 09:41:21,519] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2024-05-09 09:41:21,757] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 09:41:21,757] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:41:21,757] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:41:21,757] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 09:41:21,760] INFO App info kafka.consumer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 09:41:21,760] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2024-05-09 09:41:21,760] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:407)
[2024-05-09 09:41:21,760] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:292)
[2024-05-09 09:41:21,761] INFO [Producer clientId=connect-cluster-configs] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2024-05-09 09:41:21,763] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 09:41:21,764] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:41:21,764] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:41:21,764] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 09:41:21,764] INFO App info kafka.producer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 09:41:21,764] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2024-05-09 09:41:21,764] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2024-05-09 09:41:22,258] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 09:41:22,259] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:41:22,259] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:41:22,259] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 09:41:22,262] INFO App info kafka.consumer for connect-cluster-configs unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 09:41:22,262] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2024-05-09 09:41:22,262] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:413)
[2024-05-09 09:41:22,262] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:248)
[2024-05-09 09:41:22,264] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:269)
[2024-05-09 09:41:22,264] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:292)
[2024-05-09 09:41:22,264] INFO [Producer clientId=connect-cluster-offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1346)
[2024-05-09 09:41:22,266] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 09:41:22,266] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:41:22,267] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:41:22,267] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 09:41:22,267] INFO App info kafka.producer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 09:41:22,267] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2024-05-09 09:41:22,267] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2024-05-09 09:41:22,760] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 09:41:22,761] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:41:22,761] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:41:22,761] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 09:41:22,762] INFO App info kafka.consumer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 09:41:22,762] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:316)
[2024-05-09 09:41:22,762] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:277)
[2024-05-09 09:41:22,763] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 09:41:22,763] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:41:22,763] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 09:41:22,763] INFO App info kafka.connect for 127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 09:41:22,763] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:269)
[2024-05-09 09:41:22,764] INFO App info kafka.admin.client for connect-cluster-shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 09:41:22,765] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 09:41:22,765] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:41:22,765] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 09:41:22,766] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:386)
[2024-05-09 09:41:22,766] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:838)
[2024-05-09 09:41:22,766] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2024-05-09 09:41:25,428] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2024-05-09 09:41:25,432] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/macmkay/kafka/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 17.0.10, 17.0.10+7-Ubuntu-122.04.1
	jvm.classpath = /home/macmkay/kafka/bin/../libs/activation-1.1.1.jar:/home/macmkay/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/macmkay/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/macmkay/kafka/bin/../libs/audience-annotations-0.12.0.jar:/home/macmkay/kafka/bin/../libs/caffeine-2.9.3.jar:/home/macmkay/kafka/bin/../libs/checker-qual-3.19.0.jar:/home/macmkay/kafka/bin/../libs/commons-beanutils-1.9.4.jar:/home/macmkay/kafka/bin/../libs/commons-cli-1.4.jar:/home/macmkay/kafka/bin/../libs/commons-collections-3.2.2.jar:/home/macmkay/kafka/bin/../libs/commons-digester-2.1.jar:/home/macmkay/kafka/bin/../libs/commons-io-2.11.0.jar:/home/macmkay/kafka/bin/../libs/commons-lang3-3.8.1.jar:/home/macmkay/kafka/bin/../libs/commons-logging-1.2.jar:/home/macmkay/kafka/bin/../libs/commons-validator-1.7.jar:/home/macmkay/kafka/bin/../libs/connect-api-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-basic-auth-extension-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-json-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-mirror-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-mirror-client-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-runtime-3.7.0.jar:/home/macmkay/kafka/bin/../libs/connect-transforms-3.7.0.jar:/home/macmkay/kafka/bin/../libs/error_prone_annotations-2.10.0.jar:/home/macmkay/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/macmkay/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/macmkay/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/macmkay/kafka/bin/../libs/jackson-annotations-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-core-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-databind-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-dataformat-csv-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-datatype-jdk8-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-jaxrs-base-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-jaxrs-json-provider-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-module-jaxb-annotations-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jackson-module-scala_2.13-2.16.0.jar:/home/macmkay/kafka/bin/../libs/jakarta.activation-api-1.2.2.jar:/home/macmkay/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/macmkay/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/macmkay/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/macmkay/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/macmkay/kafka/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/home/macmkay/kafka/bin/../libs/javassist-3.29.2-GA.jar:/home/macmkay/kafka/bin/../libs/javax.activation-api-1.2.0.jar:/home/macmkay/kafka/bin/../libs/javax.annotation-api-1.3.2.jar:/home/macmkay/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/macmkay/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/macmkay/kafka/bin/../libs/jaxb-api-2.3.1.jar:/home/macmkay/kafka/bin/../libs/jersey-client-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-common-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-container-servlet-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-hk2-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jersey-server-2.39.1.jar:/home/macmkay/kafka/bin/../libs/jetty-client-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-continuation-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-http-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-io-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-security-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-server-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-servlet-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-servlets-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-util-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jetty-util-ajax-9.4.53.v20231009.jar:/home/macmkay/kafka/bin/../libs/jline-3.22.0.jar:/home/macmkay/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/macmkay/kafka/bin/../libs/jose4j-0.9.4.jar:/home/macmkay/kafka/bin/../libs/jsr305-3.0.2.jar:/home/macmkay/kafka/bin/../libs/kafka-clients-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-group-coordinator-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-log4j-appender-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-metadata-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-raft-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-server-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-server-common-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-shell-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-storage-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-storage-api-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-streams-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-streams-examples-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-streams-scala_2.13-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-streams-test-utils-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-tools-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka-tools-api-3.7.0.jar:/home/macmkay/kafka/bin/../libs/kafka_2.13-3.7.0.jar:/home/macmkay/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/macmkay/kafka/bin/../libs/maven-artifact-3.8.8.jar:/home/macmkay/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/macmkay/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/macmkay/kafka/bin/../libs/netty-buffer-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-codec-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-common-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-handler-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-resolver-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-transport-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-transport-classes-epoll-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-transport-native-epoll-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/netty-transport-native-unix-common-4.1.100.Final.jar:/home/macmkay/kafka/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/home/macmkay/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/macmkay/kafka/bin/../libs/paranamer-2.8.jar:/home/macmkay/kafka/bin/../libs/pcollections-4.0.1.jar:/home/macmkay/kafka/bin/../libs/plexus-utils-3.3.1.jar:/home/macmkay/kafka/bin/../libs/protobuf-java-3.23.4.jar:/home/macmkay/kafka/bin/../libs/reflections-0.10.2.jar:/home/macmkay/kafka/bin/../libs/reload4j-1.2.25.jar:/home/macmkay/kafka/bin/../libs/rocksdbjni-7.9.2.jar:/home/macmkay/kafka/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/home/macmkay/kafka/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/home/macmkay/kafka/bin/../libs/scala-library-2.13.12.jar:/home/macmkay/kafka/bin/../libs/scala-logging_2.13-3.9.4.jar:/home/macmkay/kafka/bin/../libs/scala-reflect-2.13.12.jar:/home/macmkay/kafka/bin/../libs/slf4j-api-1.7.36.jar:/home/macmkay/kafka/bin/../libs/slf4j-reload4j-1.7.36.jar:/home/macmkay/kafka/bin/../libs/snappy-java-1.1.10.5.jar:/home/macmkay/kafka/bin/../libs/swagger-annotations-2.2.8.jar:/home/macmkay/kafka/bin/../libs/trogdor-3.7.0.jar:/home/macmkay/kafka/bin/../libs/zookeeper-3.8.3.jar:/home/macmkay/kafka/bin/../libs/zookeeper-jute-3.8.3.jar:/home/macmkay/kafka/bin/../libs/zstd-jni-1.5.5-6.jar
	os.spec = Linux, amd64, 5.15.146.1-microsoft-standard-WSL2
	os.vcpus = 12
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2024-05-09 09:41:25,433] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2024-05-09 09:41:25,452] INFO Loading plugin from: /home/macmkay/kafka/./libs/connect-file-3.7.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,597] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/./libs/connect-file-3.7.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,598] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/jtds-1.3.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,613] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/jtds-1.3.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,617] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/slf4j-api-1.7.36.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,624] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/slf4j-api-1.7.36.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,624] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/checker-qual-3.5.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,631] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/checker-qual-3.5.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,632] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/kafka-connect-jdbc-10.7.6.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,638] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/kafka-connect-jdbc-10.7.6.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,639] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ons-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,646] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ons-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,646] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xmlparserv2-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,655] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xmlparserv2-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,655] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/oraclepki-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,664] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/oraclepki-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,664] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/postgresql-42.4.4.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,670] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/postgresql-42.4.4.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,673] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/simplefan-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,678] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/simplefan-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,678] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_cert-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,684] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_cert-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,684] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/sqlite-jdbc-3.41.2.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,688] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/sqlite-jdbc-3.41.2.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,692] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xdb-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,697] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xdb-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,697] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ucp-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,702] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ucp-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,702] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/mssql-jdbc-8.4.1.jre8.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,707] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/mssql-jdbc-8.4.1.jre8.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,811] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_core-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,824] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_core-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,824] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/common-utils-6.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,829] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/common-utils-6.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,829] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ojdbc8-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,835] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ojdbc8-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,869] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/orai18n-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,875] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/orai18n-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,875] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,880] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@1dbd16a6 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,881] INFO Scanning plugins with ServiceLoaderScanner took 429 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2024-05-09 09:41:25,882] INFO Loading plugin from: /home/macmkay/kafka/./libs/connect-file-3.7.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,929] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/./libs/connect-file-3.7.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,929] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/jtds-1.3.1.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,964] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/jtds-1.3.1.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,964] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/slf4j-api-1.7.36.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,973] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/slf4j-api-1.7.36.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,973] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/checker-qual-3.5.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:25,995] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/checker-qual-3.5.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:25,996] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/kafka-connect-jdbc-10.7.6.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:26,016] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/kafka-connect-jdbc-10.7.6.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:26,017] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ons-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:26,029] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ons-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:26,029] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xmlparserv2-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:26,132] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xmlparserv2-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:26,132] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/oraclepki-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:26,154] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/oraclepki-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:26,154] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/postgresql-42.4.4.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:26,207] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/postgresql-42.4.4.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:26,208] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/simplefan-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:26,212] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/simplefan-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:26,212] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_cert-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:26,225] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_cert-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:26,226] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/sqlite-jdbc-3.41.2.2.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:26,239] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/sqlite-jdbc-3.41.2.2.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:26,239] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xdb-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:26,250] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/xdb-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:26,250] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ucp-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:26,317] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ucp-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:26,318] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/mssql-jdbc-8.4.1.jre8.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:26,380] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/mssql-jdbc-8.4.1.jre8.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:26,386] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_core-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:26,400] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/osdt_core-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:26,400] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/common-utils-6.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:26,403] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/common-utils-6.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:26,403] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ojdbc8-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:26,548] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/ojdbc8-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:26,548] INFO Loading plugin from: /home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/orai18n-19.7.0.0.jar (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:26,555] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/orai18n-19.7.0.0.jar} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:26,555] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2024-05-09 09:41:27,341] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@1dbd16a6 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2024-05-09 09:41:27,341] INFO Scanning plugins with ReflectionScanner took 1459 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2024-05-09 09:41:27,347] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/kafka-connect-jdbc-10.7.6.jar	io.confluent.connect.jdbc.JdbcSinkConnector	sink	10.7.6
file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/kafka-connect-jdbc-10.7.6.jar	io.confluent.connect.jdbc.JdbcSourceConnector	source	10.7.6
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:122)
[2024-05-09 09:41:27,348] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,348] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,348] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,348] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,348] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,349] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,349] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,349] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,349] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,349] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,349] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,349] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,349] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,349] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,349] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,350] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,350] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,350] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,350] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,350] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,350] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,350] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,350] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,351] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,351] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,351] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,351] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,351] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,351] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,351] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,351] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,352] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,352] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,352] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,352] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,352] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,352] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,352] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,352] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,352] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,353] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,353] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,353] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,353] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,353] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,353] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,353] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,353] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,353] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,354] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,354] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,354] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,354] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2024-05-09 09:41:27,356] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,356] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,356] INFO Added alias 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,356] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,357] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,357] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,357] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,357] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,357] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,357] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,357] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,357] INFO Added alias 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,357] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,357] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,357] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,357] INFO Added alias 'FileStreamSinkConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,357] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,357] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,358] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,358] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,358] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,358] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,358] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,358] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,358] INFO Added alias 'FileStreamSourceConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,358] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,358] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,358] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,358] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,358] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,358] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,358] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,358] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,358] INFO Added alias 'JdbcSinkConnector' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,359] INFO Added alias 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,359] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,359] INFO Added alias 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,359] INFO Added alias 'JdbcSourceConnector' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,359] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,359] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,359] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,359] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,359] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,359] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,359] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,359] INFO Added alias 'ByteArrayConverter' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,359] INFO Added alias 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,359] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,359] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,359] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,360] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,360] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,360] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,360] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,360] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,360] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2024-05-09 09:41:27,390] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [./libs/connect-file-3.7.0.jar, ../confluentinc-kafka-connect-jdbc/lib]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = SASL_PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:370)
[2024-05-09 09:41:27,391] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:283)
[2024-05-09 09:41:27,393] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-05-09 09:41:27,450] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin:61)
[2024-05-09 09:41:27,470] INFO These configurations '[producer.sasl.jaas.config, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, status.storage.topic, group.id, plugin.path, consumer.sasl.mechanism, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-05-09 09:41:27,470] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:41:27,470] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:41:27,471] INFO Kafka startTimeMs: 1715222487470 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:41:27,665] INFO Kafka cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.connect.runtime.WorkerConfig:300)
[2024-05-09 09:41:27,666] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2024-05-09 09:41:27,670] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:694)
[2024-05-09 09:41:27,670] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:698)
[2024-05-09 09:41:27,671] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:704)
[2024-05-09 09:41:27,673] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:370)
[2024-05-09 09:41:27,678] INFO Logging initialized @2553ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2024-05-09 09:41:27,702] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:111)
[2024-05-09 09:41:27,703] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:182)
[2024-05-09 09:41:27,718] INFO jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 17.0.10+7-Ubuntu-122.04.1 (org.eclipse.jetty.server.Server:375)
[2024-05-09 09:41:27,735] INFO Started http_8083@22c0344e{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2024-05-09 09:41:27,735] INFO Started @2611ms (org.eclipse.jetty.server.Server:415)
[2024-05-09 09:41:27,749] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:406)
[2024-05-09 09:41:27,749] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:202)
[2024-05-09 09:41:27,749] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:406)
[2024-05-09 09:41:27,749] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:205)
[2024-05-09 09:41:27,749] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:406)
[2024-05-09 09:41:27,750] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2024-05-09 09:41:27,755] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:370)
[2024-05-09 09:41:27,766] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:41:27,767] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:41:27,767] INFO Kafka startTimeMs: 1715222487766 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:41:27,771] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:370)
[2024-05-09 09:41:27,772] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:370)
[2024-05-09 09:41:27,792] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:406)
[2024-05-09 09:41:27,799] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin:61)
[2024-05-09 09:41:27,840] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:41:27,840] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:41:27,840] INFO Kafka startTimeMs: 1715222487840 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:41:27,842] INFO Kafka Connect worker initialization took 2414ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2024-05-09 09:41:27,842] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2024-05-09 09:41:27,844] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:209)
[2024-05-09 09:41:27,845] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:369)
[2024-05-09 09:41:27,846] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:231)
[2024-05-09 09:41:27,846] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:240)
[2024-05-09 09:41:27,846] INFO Starting KafkaBasedLog with topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2024-05-09 09:41:27,849] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-05-09 09:41:27,853] INFO These configurations '[producer.sasl.jaas.config, group.id, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-05-09 09:41:27,853] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:41:27,853] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:41:27,853] INFO Kafka startTimeMs: 1715222487853 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:41:27,889] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:227)
[2024-05-09 09:41:27,898] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-05-09 09:41:27,913] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 09:41:27,915] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2024-05-09 09:41:27,916] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2024-05-09 09:41:27,916] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2024-05-09 09:41:27,936] INFO These configurations '[producer.sasl.jaas.config, group.id, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-05-09 09:41:27,937] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:41:27,937] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:41:27,937] INFO Kafka startTimeMs: 1715222487936 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:41:27,943] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-05-09 09:41:27,947] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 09:41:27,951] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 09:41:27,989] INFO These configurations '[producer.sasl.jaas.config, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-05-09 09:41:27,990] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:41:27,990] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:41:27,991] INFO Kafka startTimeMs: 1715222487990 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:41:28,004] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 09:41:28,011] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-17, connect-offsets-20, connect-offsets-11, connect-offsets-23, connect-offsets-14, connect-offsets-5, connect-offsets-0, connect-offsets-8, connect-offsets-7, connect-offsets-4, connect-offsets-1, connect-offsets-10, connect-offsets-13, connect-offsets-24, connect-offsets-21, connect-offsets-16, connect-offsets-3, connect-offsets-9, connect-offsets-15, connect-offsets-18, connect-offsets-19, connect-offsets-22, connect-offsets-6, connect-offsets-2, connect-offsets-12 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2024-05-09 09:41:28,014] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,014] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,014] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,015] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,015] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,015] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,015] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,015] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,015] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,015] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,015] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,015] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,015] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,016] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,016] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,016] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,016] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,016] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,016] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,016] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,016] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,016] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,017] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,017] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,017] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,062] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,063] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,063] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,063] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,064] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,064] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,064] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,064] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,064] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,064] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,064] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,065] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,065] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,065] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,065] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,065] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,065] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,065] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,066] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,066] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,066] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,066] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,066] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,066] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,066] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,067] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2024-05-09 09:41:28,067] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2024-05-09 09:41:28,067] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:257)
[2024-05-09 09:41:28,068] INFO Worker started (org.apache.kafka.connect.runtime.Worker:241)
[2024-05-09 09:41:28,069] INFO Starting KafkaBasedLog with topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2024-05-09 09:41:28,078] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-05-09 09:41:28,079] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 09:41:28,084] INFO These configurations '[producer.sasl.jaas.config, group.id, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-05-09 09:41:28,085] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:41:28,085] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:41:28,085] INFO Kafka startTimeMs: 1715222488084 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:41:28,086] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-05-09 09:41:28,086] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 09:41:28,092] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 09:41:28,092] INFO These configurations '[producer.sasl.jaas.config, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-05-09 09:41:28,092] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:41:28,092] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:41:28,092] INFO Kafka startTimeMs: 1715222488092 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:41:28,099] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 09:41:28,100] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-1, connect-status-3, connect-status-2, connect-status-0, connect-status-4 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2024-05-09 09:41:28,100] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,100] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,100] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,101] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,101] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,110] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,111] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,111] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,111] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,111] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,111] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2024-05-09 09:41:28,112] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2024-05-09 09:41:28,114] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:378)
[2024-05-09 09:41:28,114] INFO Starting KafkaBasedLog with topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:229)
[2024-05-09 09:41:28,121] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-05-09 09:41:28,122] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 09:41:28,125] INFO These configurations '[producer.sasl.jaas.config, group.id, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-05-09 09:41:28,126] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:41:28,126] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:41:28,126] INFO Kafka startTimeMs: 1715222488126 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:41:28,127] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-05-09 09:41:28,128] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:297)
[2024-05-09 09:41:28,132] INFO These configurations '[producer.sasl.jaas.config, plugin.path, consumer.sasl.mechanism, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, consumer.security.protocol, value.converter, key.converter, consumer.sasl.jaas.config, config.storage.topic, producer.security.protocol, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, value.converter.schemas.enable, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-05-09 09:41:28,133] INFO [Producer clientId=connect-cluster-configs] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 09:41:28,133] INFO Kafka version: 3.7.0 (org.apache.kafka.common.utils.AppInfoParser:124)
[2024-05-09 09:41:28,133] INFO Kafka commitId: 2ae524ed625438c5 (org.apache.kafka.common.utils.AppInfoParser:125)
[2024-05-09 09:41:28,133] INFO Kafka startTimeMs: 1715222488133 (org.apache.kafka.common.utils.AppInfoParser:126)
[2024-05-09 09:41:28,138] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 09:41:28,139] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:573)
[2024-05-09 09:41:28,139] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:649)
[2024-05-09 09:41:28,147] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:396)
[2024-05-09 09:41:28,187] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:286)
[2024-05-09 09:41:28,187] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:288)
[2024-05-09 09:41:28,187] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:402)
[2024-05-09 09:41:28,187] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:376)
[2024-05-09 09:41:28,198] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Cluster ID: ETD-cZSSQwOtMbFiI1xjhw (org.apache.kafka.clients.Metadata:349)
[2024-05-09 09:41:28,199] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2024-05-09 09:41:28,201] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 09:41:28,202] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 09:41:28,210] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 09:41:28,375] INFO Started o.e.j.s.ServletContextHandler@3da30ce5{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2024-05-09 09:41:28,376] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:302)
[2024-05-09 09:41:28,376] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2024-05-09 09:41:31,213] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=5, memberId='connect-127.0.1.1:8083-10c57917-592c-4c80-b428-82b7a0fbf26a', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 09:41:31,228] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=5, memberId='connect-127.0.1.1:8083-10c57917-592c-4c80-b428-82b7a0fbf26a', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 09:41:31,228] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 5 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-10c57917-592c-4c80-b428-82b7a0fbf26a', leaderUrl='http://127.0.1.1:8083/', offset=1, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 09:41:31,229] WARN [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1753)
[2024-05-09 09:41:31,229] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Current config state offset -1 is behind group assignment 1, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1826)
[2024-05-09 09:41:31,231] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1853)
[2024-05-09 09:41:31,232] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 09:41:31,232] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 09:46:27,909] INFO [AdminClient clientId=connect-cluster-shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:50:28,059] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:50:28,195] INFO [Producer clientId=connect-cluster-offsets] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:50:28,217] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:50:28,287] INFO [Producer clientId=connect-cluster-statuses] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:50:28,342] INFO [Producer clientId=connect-cluster-configs] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:50:28,560] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:50:28,560] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:50:48,159] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:02:50:48 +0000] "GET / HTTP/1.1" 200 91 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36 Edg/124.0.0.0" 78 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 09:50:50,506] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:02:50:50 +0000] "GET / HTTP/1.1" 200 91 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36 Edg/124.0.0.0" 4 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 09:51:27,988] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:54:20,117] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:02:54:20 +0000] "PUT /connectors/jdbc_source_oracle_01/config HTTP/1.1" 400 103 "-" "PostmanRuntime/7.37.0" 32 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 09:54:47,828] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:02:54:47 +0000] "PUT /connectors/jdbc_source_oracle_01/config HTTP/1.1" 400 103 "-" "PostmanRuntime/7.37.0" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 09:55:46,036] ERROR Uncaught exception in REST call to /connectors/jdbc_source_oracle_01/config (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc. JdbcSource Connector, available connectors are: PluginDesc{klass=class io.confluent.connect.jdbc.JdbcSinkConnector, name='io.confluent.connect.jdbc.JdbcSinkConnector', version='10.7.6', encodedVersion=10.7.6, type=sink, typeName='sink', location='file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/kafka-connect-jdbc-10.7.6.jar'}, PluginDesc{klass=class io.confluent.connect.jdbc.JdbcSourceConnector, name='io.confluent.connect.jdbc.JdbcSourceConnector', version='10.7.6', encodedVersion=10.7.6, type=source, typeName='source', location='file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/kafka-connect-jdbc-10.7.6.jar'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSinkConnector, name='org.apache.kafka.connect.file.FileStreamSinkConnector', version='3.7.0', encodedVersion=3.7.0, type=sink, typeName='sink', location='file:/home/macmkay/kafka/./libs/connect-file-3.7.0.jar'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSourceConnector, name='org.apache.kafka.connect.file.FileStreamSourceConnector', version='3.7.0', encodedVersion=3.7.0, type=source, typeName='source', location='file:/home/macmkay/kafka/./libs/connect-file-3.7.0.jar'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='3.7.0', encodedVersion=3.7.0, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='3.7.0', encodedVersion=3.7.0, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='3.7.0', encodedVersion=3.7.0, type=source, typeName='source', location='classpath'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:320)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:291)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$7(AbstractHerder.java:755)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1708)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:755)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:500)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$3(AbstractHerder.java:412)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 09:55:46,041] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:02:55:46 +0000] "PUT /connectors/jdbc_source_oracle_01/config HTTP/1.1" 500 2052 "-" "PostmanRuntime/7.37.0" 9 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 09:56:04,821] ERROR Uncaught exception in REST call to /connectors/jdbc_source_oracle_01/config (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSource.Connector, available connectors are: PluginDesc{klass=class io.confluent.connect.jdbc.JdbcSinkConnector, name='io.confluent.connect.jdbc.JdbcSinkConnector', version='10.7.6', encodedVersion=10.7.6, type=sink, typeName='sink', location='file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/kafka-connect-jdbc-10.7.6.jar'}, PluginDesc{klass=class io.confluent.connect.jdbc.JdbcSourceConnector, name='io.confluent.connect.jdbc.JdbcSourceConnector', version='10.7.6', encodedVersion=10.7.6, type=source, typeName='source', location='file:/home/macmkay/kafka/../confluentinc-kafka-connect-jdbc/lib/kafka-connect-jdbc-10.7.6.jar'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSinkConnector, name='org.apache.kafka.connect.file.FileStreamSinkConnector', version='3.7.0', encodedVersion=3.7.0, type=sink, typeName='sink', location='file:/home/macmkay/kafka/./libs/connect-file-3.7.0.jar'}, PluginDesc{klass=class org.apache.kafka.connect.file.FileStreamSourceConnector, name='org.apache.kafka.connect.file.FileStreamSourceConnector', version='3.7.0', encodedVersion=3.7.0, type=source, typeName='source', location='file:/home/macmkay/kafka/./libs/connect-file-3.7.0.jar'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='3.7.0', encodedVersion=3.7.0, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='3.7.0', encodedVersion=3.7.0, type=source, typeName='source', location='classpath'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='3.7.0', encodedVersion=3.7.0, type=source, typeName='source', location='classpath'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:320)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:291)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$7(AbstractHerder.java:755)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1708)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:755)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:500)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$3(AbstractHerder.java:412)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 09:56:04,823] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:02:56:04 +0000] "PUT /connectors/jdbc_source_oracle_01/config HTTP/1.1" 500 2051 "-" "PostmanRuntime/7.37.0" 6 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 09:56:28,102] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:997)
[2024-05-09 09:57:55,020] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://mysql:3306/football
	connection.user = rmoff
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [CUSTOMERS]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = oracle_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 09:57:55,023] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:370)
[2024-05-09 09:57:55,058] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_oracle_01 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2024-05-09 09:57:55,062] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2024-05-09 09:57:55,062] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2024-05-09 09:57:55,073] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=6, memberId='connect-127.0.1.1:8083-10c57917-592c-4c80-b428-82b7a0fbf26a', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2024-05-09 09:57:55,074] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:02:57:54 +0000] "PUT /connectors/jdbc_source_oracle_01/config HTTP/1.1" 201 372 "-" "PostmanRuntime/7.37.0" 78 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 09:57:55,080] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=6, memberId='connect-127.0.1.1:8083-10c57917-592c-4c80-b428-82b7a0fbf26a', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2024-05-09 09:57:55,080] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Joined group at generation 6 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-127.0.1.1:8083-10c57917-592c-4c80-b428-82b7a0fbf26a', leaderUrl='http://127.0.1.1:8083/', offset=2, connectorIds=[jdbc_source_oracle_01], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2580)
[2024-05-09 09:57:55,080] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 2 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1921)
[2024-05-09 09:57:55,082] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 09:57:55,084] INFO [jdbc_source_oracle_01|worker] Creating connector jdbc_source_oracle_01 of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 09:57:55,084] INFO [jdbc_source_oracle_01|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_oracle_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 09:57:55,085] INFO [jdbc_source_oracle_01|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_oracle_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 09:57:55,091] INFO [jdbc_source_oracle_01|worker] Instantiated connector jdbc_source_oracle_01 with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 09:57:55,092] INFO [jdbc_source_oracle_01|worker] Finished creating connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 09:57:55,093] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1950)
[2024-05-09 09:57:55,094] INFO [jdbc_source_oracle_01|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 09:57:55,095] INFO [jdbc_source_oracle_01|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://mysql:3306/football
	connection.user = rmoff
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [CUSTOMERS]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = oracle_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 09:57:55,095] INFO [jdbc_source_oracle_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 09:57:55,096] INFO [jdbc_source_oracle_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 09:57:55,099] INFO [jdbc_source_oracle_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 09:57:55,099] INFO [jdbc_source_oracle_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 09:57:55,101] INFO [jdbc_source_oracle_01|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 09:57:55,103] INFO [jdbc_source_oracle_01|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://mysql:3306/football
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 09:58:05,105] INFO [jdbc_source_oracle_01|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://mysql:3306/football
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 09:58:15,107] ERROR [jdbc_source_oracle_01|worker] WorkerConnector{id=jdbc_source_oracle_01} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://mysql:3306/football
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://mysql:3306/football
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 09:58:15,113] ERROR [jdbc_source_oracle_01|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'jdbc_source_oracle_01' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_oracle_01
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector jdbc_source_oracle_01 to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://mysql:3306/football
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://mysql:3306/football
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 09:58:15,580] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://locahost:3306/football
	connection.user = rmoff
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [CUSTOMERS]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = oracle_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 09:58:15,580] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:370)
[2024-05-09 09:58:15,591] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_oracle_01 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2024-05-09 09:58:15,591] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Handling connector-only config update by restarting connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2024-05-09 09:58:15,592] INFO [jdbc_source_oracle_01|worker] Stopping connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 09:58:15,592] INFO [jdbc_source_oracle_01|worker] Scheduled shutdown for WorkerConnector{id=jdbc_source_oracle_01} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2024-05-09 09:58:15,593] INFO [jdbc_source_oracle_01|worker] Completed shutdown for WorkerConnector{id=jdbc_source_oracle_01} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2024-05-09 09:58:15,594] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:02:58:15 +0000] "PUT /connectors/jdbc_source_oracle_01/config HTTP/1.1" 200 375 "-" "PostmanRuntime/7.37.0" 20 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 09:58:15,597] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 09:58:15,597] INFO [jdbc_source_oracle_01|worker] Creating connector jdbc_source_oracle_01 of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 09:58:15,597] INFO [jdbc_source_oracle_01|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_oracle_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 09:58:15,597] INFO [jdbc_source_oracle_01|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_oracle_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 09:58:15,598] INFO [jdbc_source_oracle_01|worker] Instantiated connector jdbc_source_oracle_01 with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 09:58:15,598] INFO [jdbc_source_oracle_01|worker] Finished creating connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 09:58:15,598] INFO [jdbc_source_oracle_01|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 09:58:15,599] INFO [jdbc_source_oracle_01|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://locahost:3306/football
	connection.user = rmoff
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [CUSTOMERS]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = oracle_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 09:58:15,599] INFO [jdbc_source_oracle_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 09:58:15,599] INFO [jdbc_source_oracle_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 09:58:15,599] INFO [jdbc_source_oracle_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 09:58:15,599] INFO [jdbc_source_oracle_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 09:58:15,600] INFO [jdbc_source_oracle_01|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 09:58:15,600] INFO [jdbc_source_oracle_01|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://locahost:3306/football
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 09:58:25,602] INFO [jdbc_source_oracle_01|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://locahost:3306/football
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 09:58:35,603] ERROR [jdbc_source_oracle_01|worker] WorkerConnector{id=jdbc_source_oracle_01} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://locahost:3306/football
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://locahost:3306/football
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 09:58:35,604] ERROR [jdbc_source_oracle_01|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'jdbc_source_oracle_01' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_oracle_01
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector jdbc_source_oracle_01 to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://locahost:3306/football
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://locahost:3306/football
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 09:58:46,354] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://192.168.1.2:3306/football
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [CUSTOMERS]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = oracle_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 09:58:46,355] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:370)
[2024-05-09 09:58:46,360] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_oracle_01 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2024-05-09 09:58:46,360] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Handling connector-only config update by restarting connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2024-05-09 09:58:46,360] INFO [jdbc_source_oracle_01|worker] Stopping connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 09:58:46,360] INFO [jdbc_source_oracle_01|worker] Scheduled shutdown for WorkerConnector{id=jdbc_source_oracle_01} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2024-05-09 09:58:46,361] INFO [jdbc_source_oracle_01|worker] Completed shutdown for WorkerConnector{id=jdbc_source_oracle_01} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2024-05-09 09:58:46,361] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:02:58:46 +0000] "PUT /connectors/jdbc_source_oracle_01/config HTTP/1.1" 200 377 "-" "PostmanRuntime/7.37.0" 10 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 09:58:46,362] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 09:58:46,362] INFO [jdbc_source_oracle_01|worker] Creating connector jdbc_source_oracle_01 of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 09:58:46,363] INFO [jdbc_source_oracle_01|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_oracle_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 09:58:46,363] INFO [jdbc_source_oracle_01|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_oracle_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 09:58:46,364] INFO [jdbc_source_oracle_01|worker] Instantiated connector jdbc_source_oracle_01 with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 09:58:46,364] INFO [jdbc_source_oracle_01|worker] Finished creating connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 09:58:46,364] INFO [jdbc_source_oracle_01|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 09:58:46,365] INFO [jdbc_source_oracle_01|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://192.168.1.2:3306/football
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [CUSTOMERS]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = oracle_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 09:58:46,365] INFO [jdbc_source_oracle_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 09:58:46,365] INFO [jdbc_source_oracle_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 09:58:46,365] INFO [jdbc_source_oracle_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 09:58:46,365] INFO [jdbc_source_oracle_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 09:58:46,366] INFO [jdbc_source_oracle_01|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 09:58:46,367] INFO [jdbc_source_oracle_01|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/football
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 09:58:56,368] INFO [jdbc_source_oracle_01|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/football
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 09:59:06,369] ERROR [jdbc_source_oracle_01|worker] WorkerConnector{id=jdbc_source_oracle_01} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/football
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/football
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 09:59:06,370] ERROR [jdbc_source_oracle_01|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'jdbc_source_oracle_01' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_oracle_01
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector jdbc_source_oracle_01 to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/football
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/football
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 09:59:13,239] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://192.168.1.2:3306/tai_khoan
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [taikhoan]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = oracle_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 09:59:13,240] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:370)
[2024-05-09 09:59:13,244] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Connector jdbc_source_oracle_01 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2384)
[2024-05-09 09:59:13,245] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Handling connector-only config update by restarting connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:715)
[2024-05-09 09:59:13,245] INFO [jdbc_source_oracle_01|worker] Stopping connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.Worker:420)
[2024-05-09 09:59:13,245] INFO [jdbc_source_oracle_01|worker] Scheduled shutdown for WorkerConnector{id=jdbc_source_oracle_01} (org.apache.kafka.connect.runtime.WorkerConnector:267)
[2024-05-09 09:59:13,246] INFO [jdbc_source_oracle_01|worker] Completed shutdown for WorkerConnector{id=jdbc_source_oracle_01} (org.apache.kafka.connect.runtime.WorkerConnector:287)
[2024-05-09 09:59:13,246] INFO [0:0:0:0:0:0:0:1] - - [09/May/2024:02:59:13 +0000] "PUT /connectors/jdbc_source_oracle_01/config HTTP/1.1" 200 377 "-" "PostmanRuntime/7.37.0" 9 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-05-09 09:59:13,247] INFO [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Starting connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2039)
[2024-05-09 09:59:13,247] INFO [jdbc_source_oracle_01|worker] Creating connector jdbc_source_oracle_01 of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:309)
[2024-05-09 09:59:13,247] INFO [jdbc_source_oracle_01|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_oracle_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-05-09 09:59:13,247] INFO [jdbc_source_oracle_01|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = jdbc_source_oracle_01
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-05-09 09:59:13,248] INFO [jdbc_source_oracle_01|worker] Instantiated connector jdbc_source_oracle_01 with version 10.7.6 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:331)
[2024-05-09 09:59:13,248] INFO [jdbc_source_oracle_01|worker] Finished creating connector jdbc_source_oracle_01 (org.apache.kafka.connect.runtime.Worker:352)
[2024-05-09 09:59:13,248] INFO [jdbc_source_oracle_01|worker] Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2024-05-09 09:59:13,248] INFO [jdbc_source_oracle_01|worker] JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://192.168.1.2:3306/tai_khoan
	connection.user = root
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 10000
	query = 
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = [taikhoan]
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = oracle_
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:370)
[2024-05-09 09:59:13,248] INFO [jdbc_source_oracle_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 09:59:13,248] INFO [jdbc_source_oracle_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 09:59:13,248] INFO [jdbc_source_oracle_01|worker] Validating JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:171)
[2024-05-09 09:59:13,248] INFO [jdbc_source_oracle_01|worker] Validated JDBC URL. (io.confluent.connect.jdbc.dialect.DatabaseDialects:174)
[2024-05-09 09:59:13,249] INFO [jdbc_source_oracle_01|worker] Initial connection attempt with the database. (io.confluent.connect.jdbc.JdbcSourceConnector:94)
[2024-05-09 09:59:13,249] INFO [jdbc_source_oracle_01|worker] Unable to connect to database on attempt 1/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 09:59:23,251] INFO [jdbc_source_oracle_01|worker] Unable to connect to database on attempt 2/3. Will retry in 10000 ms. (io.confluent.connect.jdbc.util.CachedConnectionProvider:90)
java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-05-09 09:59:33,253] ERROR [jdbc_source_oracle_01|worker] WorkerConnector{id=jdbc_source_oracle_01} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:200)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
[2024-05-09 09:59:33,254] ERROR [jdbc_source_oracle_01|worker] [Worker clientId=connect-127.0.1.1:8083, groupId=connect-cluster] Failed to start connector 'jdbc_source_oracle_01' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2075)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_oracle_01
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$41(DistributedHerder.java:2045)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:360)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:144)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:122)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector jdbc_source_oracle_01 to state STARTED
	... 9 more
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:62)
	at io.confluent.connect.jdbc.JdbcSourceConnector.start(JdbcSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:192)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:217)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:376)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:357)
	... 8 more
Caused by: java.sql.SQLException: No suitable driver found for jdbc:mysql://192.168.1.2:3306/tai_khoan
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:706)
	at java.sql/java.sql.DriverManager.getConnection(DriverManager.java:190)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.getConnection(GenericDatabaseDialect.java:256)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.newConnection(CachedConnectionProvider.java:84)
	at io.confluent.connect.jdbc.util.CachedConnectionProvider.getConnection(CachedConnectionProvider.java:54)
	... 13 more
